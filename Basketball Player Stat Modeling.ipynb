{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NBA Season Stat Predictions Pipeline\n",
    "\n",
    "\n",
    "# Overview of steps\n",
    "\n",
    "# 1. Build Model\n",
    "\n",
    "1. Data Pull (WebScraper) \n",
    "    1. Experienced Players (www.basketball-reference.com)\n",
    "    2. Rookies (www.sports-reference.com)\n",
    "2. Data Cleaning\n",
    "3. Feature Engineering\n",
    "    1. Experienced Players (3+ Years Exp)\n",
    "    2. Inexperienced Players (1-2 Years Exp)\n",
    "    3. Rookies\n",
    "4. Data Preprocessing\n",
    "    1. Experienced Players\n",
    "    2. Inexperienced Players\n",
    "    3. Rookies\n",
    "5. Modeling\n",
    "    1. Regression\n",
    "    2. Weighted Average\n",
    "    3. Average % Change\n",
    "6. Evaluate Model Performance\n",
    "\n",
    "# 2. Make Predictions\n",
    "1. Call Functions To Train Models and Process Predictions\n",
    "\n",
    "\n",
    "# 3. Compare Predictions to Actual\n",
    "1. Pull Latest Year Data\n",
    "2. Compare Predicted vs Actual\n",
    "\n",
    "# Bonus: Modeling Tuning and Analysis Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "- Years Pro Now needs to have 1 added to it - CAN JUST BE YEARS PRO PRIOR\n",
    "- Games Started and Games needs to be changed to Prior Year Games Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Data Pull (WebScraper) \n",
    "\n",
    "**A. Experienced Players**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20299, 30)"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from urllib.request import urlopen\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from array import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "year_to_loop = []\n",
    "year = 1980\n",
    "for i in range(40):\n",
    "    year_to_loop.append(str(year))\n",
    "    year+=1\n",
    "\n",
    "years = []\n",
    "players_list_agg = []\n",
    "holder = 0\n",
    "\n",
    "for year in year_to_loop:\n",
    "    url = 'https://www.basketball-reference.com/leagues/NBA_'+year+'_per_game.html'\n",
    "    headers= {'User-Agent': 'Mozilla/5.0'}\n",
    "    response = requests.get(url, headers = headers)\n",
    "    response.status_code\n",
    "    response.content\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    stat_table = soup.find_all('table', class_ = 'stats_table')\n",
    "    stat_table = stat_table[0]\n",
    "\n",
    "    players_list = []\n",
    "    for row in stat_table.find_all('tr'):\n",
    "        for cell in row.find_all('td'):\n",
    "            players_list_agg.append(cell.text)\n",
    "            players_list.append(cell.text)\n",
    "    \n",
    "    holder += len(players_list)\n",
    "    headers_list = [th.getText() for th in soup.findAll('tr',limit=2)[0].findAll('th')]\n",
    "    for i in range(int((int(len(players_list)))/(int(len(headers_list)-1)))):\n",
    "        years.append(year)\n",
    "    \n",
    "headers_list = [th.getText() for th in soup.findAll('tr',limit=2)[0].findAll('th')]\n",
    "headers_list = headers_list[1:]\n",
    "headers_list.insert(0,'Year')\n",
    "\n",
    "players = numpy.asarray(players_list_agg)\n",
    "players = numpy.reshape(players,( int( len(players_list_agg) / (len(headers_list)-1) ) , int( len(headers_list)-1 ) ))\n",
    "\n",
    "years = numpy.asarray(years)\n",
    "years = numpy.reshape(years,( int( len(years) ), 1 ))\n",
    "\n",
    "headers = numpy.asarray(headers_list)\n",
    "headers = numpy.reshape(headers,(1,len(headers_list)))\n",
    "\n",
    "players_years = numpy.concatenate((years,players),1)\n",
    "players_headers = numpy.concatenate((headers, players_years), 0)\n",
    "\n",
    "NBA_Stats = pd.DataFrame(players_headers)\n",
    "NBA_Stats.columns = NBA_Stats.iloc[0]\n",
    "NBA_Stats = NBA_Stats[1:]\n",
    "\n",
    "NBA_Stats.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B. Rookies**\n",
    "\n",
    "Here, rather than pull all rookie data from the website, we're taking our Experienced player data, finding their rookie year, and searching for their college stats using the webscrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_year = pd.DataFrame(NBA_Stats.groupby('Player')['Year'].min())\n",
    "min_year = min_year[(min_year.Year != '1980')&(min_year.Year != '1981')]\n",
    "min_year = min_year.rename(columns={'Year':'Rookie_Year'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rookies_agg = numpy.zeros((0,29), dtype=numpy.dtype('U100'))\n",
    "rookies_agg = numpy.asarray(rookies_agg)\n",
    "rookies_agg = numpy.reshape(rookies_agg,(0,29))\n",
    "\n",
    "for player in min_year.index:\n",
    "    player_search = player.replace('.','')\n",
    "    player_search = player_search.replace(' ','-')\n",
    "    url = 'https://www.sports-reference.com/cbb/players/'+player_search.lower()+'-1.html'\n",
    "    hdrs= {'User-Agent': 'Mozilla/5.0'}\n",
    "    response = requests.get(url, headers = hdrs)\n",
    "    response.status_code\n",
    "    response.content\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        stat_table = soup.find_all('table', class_ = 'stats_table')\n",
    "        stat_table = stat_table[0]\n",
    "        stats = []\n",
    "        for row in stat_table.find_all('tr'):\n",
    "            for cell in row.find_all('td'):\n",
    "                stats.append(cell.text)\n",
    "        stats = stats[-28:]\n",
    "        stats.insert(0,player)\n",
    "        stats = numpy.asarray(stats[0:29])\n",
    "        stats = numpy.asarray(stats)\n",
    "        stats = numpy.reshape(stats,(1,29))\n",
    "        rookies_agg = numpy.concatenate((rookies_agg,stats),0)\n",
    "\n",
    "        headers_list = [th.getText() for th in soup.findAll('tr',limit=2)[0].findAll('th')]\n",
    "        headers_list.insert(1,'Player')\n",
    "headers_list = headers_list[1:30]\n",
    "headers_list = numpy.asarray(headers_list)\n",
    "headers_list = numpy.reshape(headers_list,(1,29))\n",
    "player_stats = numpy.concatenate((headers_list, rookies_agg),0)\n",
    "rookies = pd.DataFrame(player_stats)\n",
    "rookies.columns = rookies.loc[0]\n",
    "rookies = rookies.loc[1:]\n",
    "rookies = pd.merge(min_year, rookies, how = 'inner',left_on =['Player'],right_on=['Player'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2235, 30)"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rookies.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Data Cleaning\n",
    "\n",
    "- Removing players who didn't play at least 20 games (~1k rows)\n",
    "- Removing Excess rows for players who played on multiple teams and keeping total (~2k rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14219, 30)"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NBA_Stats = NBA_Stats[NBA_Stats['G'].astype(int) > 19]\n",
    "\n",
    "for player, year in NBA_Stats.loc[NBA_Stats['Tm']=='TOT'][['Player','Year']].itertuples(index=False):\n",
    "    NBA_Stats = NBA_Stats.drop(NBA_Stats[(NBA_Stats['Player'] == player) & (NBA_Stats['Tm'] != 'TOT')& (NBA_Stats['Year'] == year)].index)\n",
    "\n",
    "NBA_Stats.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 Feature Engineering\n",
    "\n",
    "**A. Experienced Players 3+ Years**\n",
    "\n",
    "Adding the following variables:\n",
    "- 1 Year Prior Data\n",
    "- 2 Years Prior Data\n",
    "- 3 Years Prior Data\n",
    "- Position\n",
    "- Traded\n",
    "- Starter\n",
    "- Years Pro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prior Year, 2 Years Prior, and 3 Years Prior**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 YEAR PRIOR\n",
    "df_py = NBA_Stats.copy()\n",
    "df_py['PY'] = df_py['Year'].astype(int)+1\n",
    "df_py['PY'] = df_py['PY'].astype(str)\n",
    "df_py = df_py.rename(columns={'G':'G1','GS':'GS1',\"MP\":\"MP1\",\"PTS\":\"PTS1\",\"Tm\":\"Tm1\",\"FGA\":\"FGA1\",\"3PA\":\"3PA1\",\"eFG\":\"eFG1\",\"FTA\":\"FTA1\",\"FT\":\"FT1\",\"TRB\":\"TRB1\",\"AST\":\"AST1\",\"STL\":\"STL1\",\"BLK\":\"BLK1\",\"TOV\":\"TOV1\",\"eFG%\":\"eFG%1\",\"3p%\":\"3P%1\",\"FT%\":\"FT%1\",\"FG%\":\"FG%1\",\"3P%\":\"3P%1\"})\n",
    "features_exp = pd.merge(NBA_Stats,df_py[['Player','PY','G1','GS1','MP1','PTS1','Tm1','FGA1','FG%1','3PA1','3P%1','eFG%1','FTA1','FT%1','TRB1','AST1','STL1','BLK1','TOV1']],how='left',left_on = ['Player','Year'], right_on=['Player','PY'])\n",
    "# 2 YEARS PRIOR\n",
    "df_py2 = NBA_Stats.copy()\n",
    "df_py2['PY2'] = df_py2['Year'].astype(int)+2\n",
    "df_py2['PY2'] = df_py2['PY2'].astype(str)\n",
    "df_py2 = df_py2.rename(columns={\"MP\":\"MP2\",\"PTS\":\"PTS2\",\"Tm\":\"Tm2\",\"FGA\":\"FGA2\",\"3PA\":\"3PA2\",\"eFG\":\"eFG2\",\"FTA\":\"FTA2\",\"FT\":\"FT2\",\"TRB\":\"TRB2\",\"AST\":\"AST2\",\"STL\":\"STL2\",\"BLK\":\"BLK2\",\"TOV\":\"TOV2\",\"eFG%\":\"eFG%2\",\"3p%\":\"3P%2\",\"FT%\":\"FT%2\",\"FG%\":\"FG%2\",\"3P%\":\"3P%2\"})\n",
    "features_exp = pd.merge(features_exp,df_py2[['Player','PY2','MP2','PTS2','Tm2','FGA2','FG%2','3PA2','3P%2','eFG%2','FTA2','FT%2','TRB2','AST2','STL2','BLK2','TOV2']],how='left',left_on = ['Player','Year'], right_on=['Player','PY2'])\n",
    "# 3 YEARS PRIOR\n",
    "df_py3 = NBA_Stats.copy()\n",
    "df_py3['PY3'] = df_py3['Year'].astype(int)+3\n",
    "df_py3['PY3'] = df_py3['PY3'].astype(str)\n",
    "df_py3 = df_py3.rename(columns={\"MP\":\"MP3\",\"PTS\":\"PTS3\",\"Tm\":\"Tm3\",\"FGA\":\"FGA3\",\"3PA\":\"3PA3\",\"eFG\":\"eFG3\",\"FTA\":\"FTA3\",\"FT\":\"FT3\",\"TRB\":\"TRB3\",\"AST\":\"AST3\",\"STL\":\"STL3\",\"BLK\":\"BLK3\",\"TOV\":\"TOV3\",\"eFG%\":\"eFG%3\",\"3p%\":\"3P%3\",\"FT%\":\"FT%3\",\"FG%\":\"FG%3\",\"3P%\":\"3P%3\"})\n",
    "features_exp = pd.merge(features_exp,df_py3[['Player','PY3','MP3','PTS3','Tm3','FGA3','FG%3','3PA3','3P%3','eFG%3','FTA3','FT%3','TRB3','AST3','STL3','BLK3','TOV3']],how='left',left_on = ['Player','Year'], right_on=['Player','PY3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Positions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing C-PF, PF-C, PG-SG, etc instances (Coult try keeping those)\n",
    "features_exp.Pos = features_exp.Pos.apply(lambda x: x[:2].replace(' ','').replace('-','') if len(x) > 2 else x)\n",
    "positions = pd.get_dummies(features_exp.Pos)\n",
    "#Rename PF to Fouls\n",
    "features_exp = features_exp.rename(columns={'PF':'Fouls'})\n",
    "features_exp = features_exp.join(positions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Traded**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "traded = []\n",
    "\n",
    "for ct, pt in features_exp[['Tm','Tm1']].itertuples(index=False):\n",
    "    if pd.isna(pt):\n",
    "        traded.append(0)\n",
    "    elif ct != pt:\n",
    "        traded.append(1)\n",
    "    else:\n",
    "        traded.append(0)\n",
    "        \n",
    "features_exp['Traded'] = traded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Starter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_exp['Starter'] = features_exp.GS.replace('',np.nan).astype(float).apply(lambda x: 1 if x >= 40 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Years Pro**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Dataframe with Minimum Year value for each player\n",
    "df_yearspro = pd.DataFrame(features_exp.groupby('Player')['Year'].min())\n",
    "df_yearspro['Player'] = df_yearspro.index\n",
    "df_yearspro.index = df_yearspro.index.rename('index')\n",
    "df_yearspro['Min_Year'] = df_yearspro.Year\n",
    "#Subtract Minimum Year from Current Year\n",
    "features_exp = pd.merge(features_exp,df_yearspro[['Player','Min_Year']],how = 'inner', left_on=['Player'], right_on=['Player'] )\n",
    "features_exp['Years_Pro'] = features_exp.Year.astype(int) - features_exp.Min_Year.astype(int)\n",
    "features_exp = features_exp.drop(['Min_Year'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Year', 'Player', 'Pos', 'Age', 'Tm', 'G', 'GS', 'MP', 'FG', 'FGA',\n",
       "       'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA',\n",
       "       'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'Fouls', 'PTS',\n",
       "       'PY', 'G1', 'GS1', 'MP1', 'PTS1', 'Tm1', 'FGA1', 'FG%1', '3PA1', '3P%1',\n",
       "       'eFG%1', 'FTA1', 'FT%1', 'TRB1', 'AST1', 'STL1', 'BLK1', 'TOV1', 'PY2',\n",
       "       'MP2', 'PTS2', 'Tm2', 'FGA2', 'FG%2', '3PA2', '3P%2', 'eFG%2', 'FTA2',\n",
       "       'FT%2', 'TRB2', 'AST2', 'STL2', 'BLK2', 'TOV2', 'PY3', 'MP3', 'PTS3',\n",
       "       'Tm3', 'FGA3', 'FG%3', '3PA3', '3P%3', 'eFG%3', 'FTA3', 'FT%3', 'TRB3',\n",
       "       'AST3', 'STL3', 'BLK3', 'TOV3', 'C', 'PF', 'PG', 'SF', 'SG', 'Traded',\n",
       "       'Starter', 'Years_Pro'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_exp.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.4 Data Preprocessing\n",
    "\n",
    "- 3+ Years Exp\n",
    "- 1-2 Years Exp\n",
    "- Rookies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A. 3+ Years Exp**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14319, 88)"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_exp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B. 1-2 Years Exp**\n",
    "\n",
    "Creating a Features dataframe for players with less than 3 years experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_inexp = features_exp[(features_exp.Years_Pro <= 2) & (features_exp.Years_Pro >= 1)][['Year', 'Player', 'Pos', 'Age', 'Tm', 'G', 'GS', 'MP', 'FG', 'FGA',\n",
    "       'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA',\n",
    "       'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'Fouls', 'PTS',\n",
    "       'PY', 'G1', 'GS1', 'MP1', 'PTS1', 'Tm1', 'FGA1', 'FG%1', '3PA1', '3P%1',\n",
    "       'eFG%1', 'FTA1', 'FT%1', 'TRB1', 'AST1', 'STL1', 'BLK1', 'TOV1','C', 'PF', 'PG', 'SF', 'SG', 'Traded',\n",
    "       'Starter', 'Years_Pro']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C. Rookies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "rookies = rookies.rename(columns={'PTS':'Rookie_PTS','TRB':'Rookie_TRB','AST':'Rookie_AST',\n",
    "                                  'MP':'Rookie_MP','FG%':'Rookie_FG%','FT%':'Rookie_FT%',\n",
    "                                  'STL':'Rookie_STL','TOV':'Rookie_TOV', 'BLK':'Rookie_BLK'})\n",
    "rookies = pd.merge(NBA_Stats[['Player','Year','PTS','TRB','AST','MP','FG%','FT%','STL','BLK','TOV']], rookies, how ='inner',left_on=['Player','Year'],right_on=['Player','Rookie_Year'])\n",
    "features_rookies = rookies[['Player','Year','PTS','TRB','AST','MP','FG%','FT%','STL','BLK','TOV','G', 'GS', \n",
    "                            'Rookie_MP', 'FG', 'FGA','Rookie_FG%', '2P', '2PA', '2P%', '3P', '3PA', '3P%', 'FT', \n",
    "                            'FTA', 'Rookie_FT%','ORB', 'DRB', 'Rookie_TRB', 'Rookie_AST', 'Rookie_STL', \n",
    "                            'Rookie_BLK', 'Rookie_TOV', 'Rookie_PTS', 'SOS']].copy()\n",
    "features_rookies['G'] = features_rookies['G'].apply(lambda x: np.nan if x.isnumeric() == False else x)\n",
    "features_rookies['2P'] = features_rookies['2P'].apply(lambda x: np.nan if x.isalpha() == True else x)\n",
    "features_rookies = features_rookies.replace('','0').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Rookie_MP', 'Rookie_FG%', 'Rookie_FT%', 'Rookie_TRB', 'Rookie_AST',\n",
       "       'Rookie_STL', 'Rookie_BLK', 'Rookie_TOV', 'Rookie_PTS', 'SOS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_exp.drop(current_year_stats,axis=1, errors='ignore').dropna().columns\n",
    "features_rookies.drop(current_year_stats,axis=1, errors='ignore').dropna().columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.5 Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A. Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pylab\n",
    "import math\n",
    "\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats import diagnostic as diag\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from lightgbm import LGBMRegressor \n",
    "from xgboost import XGBRegressor \n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.linear_model import RidgeCV, Ridge\n",
    "\n",
    "import warnings\n",
    "def ignore_warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.warn = ignore_warn #ignore annoying warning (from sklearn and seaborn)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def RMSE(actual, prediction):\n",
    "    mse = mean_squared_error(actual,prediction)\n",
    "    rmse = math.sqrt(mse)\n",
    "    return(rmse)\n",
    "\n",
    "current_year_stats = ['Year', 'Player', 'Pos', 'Tm', 'G', 'GS', 'MP', 'FG', 'FGA',\n",
    "       'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA',\n",
    "       'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'Fouls', 'PTS',\n",
    "       'PY','PY2','PY3','Tm1','Tm2','Tm3']\n",
    "current_year_stats_no_player = ['Year', 'Pos', 'Tm', 'G', 'GS', 'MP', 'FG', 'FGA',\n",
    "       'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA',\n",
    "       'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'Fouls', 'PTS',\n",
    "       'PY','PY2','PY3','Tm1','Tm2','Tm3']\n",
    "\n",
    "alphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\n",
    "alphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\n",
    "e_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\n",
    "e_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\n",
    "\n",
    "stats_to_predict = ['PTS','TRB','AST','FG%','FT%','STL','BLK','TOV']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regression Models Used**\n",
    "\n",
    "- Random Forest\n",
    "- Linear Regression\n",
    "- Lasso Regressor\n",
    "- Ridge Regressor\n",
    "- Elastic Regressor\n",
    "- Kernel Ridge Regressor\n",
    "- GBoost Regressor\n",
    "- XGBoost Regressor\n",
    "- LightGBM Regressor\n",
    "- Stacking CV Regressor\n",
    "\n",
    "Because we are predicting 8 stats for 3 different groups (24 total) I decided to just use all variables in all our models and \"mass predict\". A better approach may be to create each model seperatley and pickle the models, but in order to save I put them all in 1 function. I've added a section at the end where you can play with each model seperately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model_RMSE(features_train, features_predict, stats):\n",
    "    \n",
    "    df_rmse = pd.DataFrame()\n",
    "    df_predictions = pd.DataFrame()\n",
    "    \n",
    "    for stat in stats:\n",
    "        \n",
    "        model_list = []\n",
    "        rmse_list = []\n",
    "        \n",
    "        stat_features = features_train.drop(current_year_stats,axis=1, errors='ignore').dropna()\n",
    "        stat_features = stat_features.replace('','0').astype(float)\n",
    "\n",
    "        target = features_train.dropna()\n",
    "        target = target[stat].replace('','0').astype(float)\n",
    "\n",
    "        ### BUILD AND TRAIN MODELS ###\n",
    "        \n",
    "        x_train, x_test, y_train, y_test = train_test_split(stat_features, target,test_size = .2)\n",
    "        #RANDOM FOREST\n",
    "        rf_regressor = RandomForestRegressor()\n",
    "        rf_regressor.fit(x_train, y_train)\n",
    "        model_list.append('Random Forest')\n",
    "        rmse_list.append(RMSE(rf_regressor.predict(x_test), y_test))\n",
    "        #LINEAR REGRESSION\n",
    "        rm_regressor = LinearRegression()\n",
    "        rm_regressor.fit(x_train,y_train)\n",
    "        model_list.append('Linear Regressor')\n",
    "        rmse_list.append(RMSE(rm_regressor.predict(x_test), y_test))\n",
    "        #LASSO\n",
    "        lasso = Lasso()\n",
    "        kfolds = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "        lasso_regressor = make_pipeline(RobustScaler(), LassoCV(max_iter=1e7, alphas=alphas2, random_state=42, cv=kfolds))\n",
    "        lasso_regressor.fit(x_train,y_train)\n",
    "        model_list.append('Lasso Regressor')\n",
    "        rmse_list.append(RMSE(lasso_regressor.predict(x_test), y_test))\n",
    "        #RIDGE\n",
    "        ridge = Ridge()\n",
    "        params = {'alpha':[10, 20, 50,1e1, 1e2, 1e3, 1e5]}\n",
    "        ridge_regressor = GridSearchCV(ridge, params, scoring = 'neg_mean_squared_error',cv=5)\n",
    "        ridge_regressor.fit(x_train,y_train)\n",
    "        model_list.append('Ridge Regressor')\n",
    "        rmse_list.append(RMSE(ridge_regressor.predict(x_test), y_test))\n",
    "        #ELASTIC\n",
    "        elastic = ElasticNet()\n",
    "        params = {'alpha':[1e-15,1e-10, 1e-8, 1e-4, 1e-3, 1e-2,1, 5, 10, 20, 50,1e1, 1e2, 1e3, 1e5]}\n",
    "        elastic_regressor = GridSearchCV(elastic, params, scoring = 'neg_mean_squared_error',cv=5)\n",
    "        elastic_regressor.fit(x_train, y_train)\n",
    "        model_list.append('Elastic Regressor')\n",
    "        rmse_list.append(RMSE(elastic_regressor.predict(x_test), y_test))\n",
    "        #KERNEL RIDGE\n",
    "        krr = KernelRidge(alpha=1000)\n",
    "        params = {'alpha':[0,1]}\n",
    "        krr_regressor = GridSearchCV(krr, params, scoring = 'neg_mean_squared_error',cv=5)\n",
    "        krr_regressor.fit(x_train, y_train)\n",
    "        model_list.append('KRR Regressor')\n",
    "        rmse_list.append(RMSE(krr_regressor.predict(x_test), y_test))\n",
    "        #GBOOST\n",
    "        gboost = GradientBoostingRegressor()\n",
    "        gboost_regressor = gboost.fit(x_train,y_train)\n",
    "        model_list.append('GBoost Regressor')\n",
    "        rmse_list.append(RMSE(gboost_regressor.predict(x_test), y_test))\n",
    "        #XGBOOST\n",
    "        from xgboost import XGBRegressor\n",
    "        xgboost = XGBRegressor(learning_rate=0.05,n_estimators=475, max_depth=3, min_child_weight=0,\n",
    "                                             gamma=0, subsample=0.5, colsample_bytree=1, objective='reg:squarederror', \n",
    "                                             nthread=-1, scale_pos_weight=1, seed=20, reg_alpha=1e-5)\n",
    "        xgboost_regressor = xgboost.fit(x_train.values,y_train.values)\n",
    "        model_list.append('XGBoost Regressor')\n",
    "        rmse_list.append(RMSE(xgboost_regressor.predict(x_test.values), y_test.values))\n",
    "        #LIGHT GBM\n",
    "        lightgbm = LGBMRegressor()\n",
    "        params = {'alpha':[1e-15,1e-10, 1e-8, 1e-4, 1e-3, 1e-2,1, 5, 10, 20, 50,1e1, 1e2, 1e3, 1e5]}\n",
    "        lightgbm_regressor = GridSearchCV(lightgbm, params, scoring = 'neg_mean_squared_error',cv=5)\n",
    "        lightgbm_regressor.fit(x_train, y_train)\n",
    "        model_list.append('LightGBM Regressor')\n",
    "        rmse_list.append(RMSE(lightgbm_regressor.predict(x_test), y_test))\n",
    "        #STACKING CV REGRESSOR\n",
    "        stack_gen = StackingCVRegressor(regressors=(rm_regressor, rf_regressor, ridge_regressor, lasso_regressor, elastic_regressor, krr_regressor, gboost_regressor, xgboost_regressor, lightgbm_regressor),\n",
    "                                        meta_regressor=xgboost,\n",
    "                                        use_features_in_secondary=True)\n",
    "        stack_gen_model = stack_gen.fit(x_train, y_train)\n",
    "        model_list.append('Stacking CV Regressor')\n",
    "        rmse_list.append(RMSE(stack_gen_model.predict(np.array(x_test)), y_test))\n",
    "        stack_gen_model_list = []\n",
    "        for i in stack_gen_model.predict(np.array(x_test)):\n",
    "            a = []\n",
    "            a.append(i)\n",
    "            stack_gen_model_list.append(a)\n",
    "        stack_gen_model_array = np.asarray(stack_gen_model_list)\n",
    "        #ALL MODELS COMBINED\n",
    "        n=10\n",
    "        all_models = list(map(sum, zip(rm_regressor.predict(x_test) * 1/n, \n",
    "                          rf_regressor.predict(x_test) * 1/n,\n",
    "                          ridge_regressor.predict(x_test) * 1/n,\n",
    "                          lasso_regressor.predict(x_test) * 1/n,\n",
    "                          elastic_regressor.predict(x_test) * 1/n,\n",
    "                          krr_regressor.predict(x_test) * 1/n,\n",
    "                          gboost_regressor.predict(x_test) * 1/n,\n",
    "                          xgboost_regressor.predict(x_test.values) * 1/n , \n",
    "                          lightgbm_regressor.predict(x_test) * 1/n,\n",
    "                          stack_gen_model_array * 1/n,\n",
    "                           )))\n",
    "        model_list.append('All Models Combined')\n",
    "        rmse_list.append(RMSE(all_models, y_test))\n",
    "        \n",
    "        ### RMSE DATAFRAME ###\n",
    "        \n",
    "        df_rmse['Model'] = model_list\n",
    "        df_rmse[stat] = rmse_list\n",
    "        \n",
    "        ### MAKE PREDICTIONS ###\n",
    "        \n",
    "\n",
    "        #prediction_features = features_predict.drop(current_year_stats,axis=1, errors='ignore').dropna()\n",
    "        #prediction_features = prediction_features.replace('','0').astype(float)\n",
    "        prediction_features = features_predict.drop(['Player'],axis=1, errors='ignore').dropna()\n",
    "        prediction_features = prediction_features.replace('','0').astype(float)\n",
    "        \n",
    "        stack_gen_predict_list = []\n",
    "        for i in stack_gen_model.predict(np.array(prediction_features)):\n",
    "            a = []\n",
    "            a.append(i)\n",
    "            stack_gen_predict_list.append(a)\n",
    "        stack_gen_array = np.asarray(stack_gen_predict_list)\n",
    "        \n",
    "        regression_predictions = list(map(sum, zip(rm_regressor.predict(prediction_features) * 1/n, \n",
    "                          rf_regressor.predict(prediction_features) * 1/n,\n",
    "                          ridge_regressor.predict(prediction_features) * 1/n,\n",
    "                          lasso_regressor.predict(prediction_features) * 1/n,\n",
    "                          elastic_regressor.predict(prediction_features) * 1/n,\n",
    "                          krr_regressor.predict(prediction_features) * 1/n,\n",
    "                          gboost_regressor.predict(prediction_features) * 1/n,\n",
    "                          xgboost_regressor.predict(prediction_features.values) * 1/n , \n",
    "                          lightgbm_regressor.predict(prediction_features) * 1/n,\n",
    "                          stack_gen_array * 1/n,\n",
    "                           )))\n",
    "        features_predict_player = features_predict.dropna()\n",
    "        df_predictions['Player'] = features_predict_player.Player\n",
    "        df_predictions['Regression_'+stat] = regression_predictions\n",
    "        df_predictions['Regression_'+stat] = df_predictions['Regression_'+stat].astype(float)\n",
    "\n",
    "        print(stat)\n",
    "    return df_rmse, df_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PTS\n",
      "TRB\n",
      "AST\n",
      "FG%\n",
      "FT%\n",
      "STL\n",
      "BLK\n",
      "TOV\n"
     ]
    }
   ],
   "source": [
    "rmse_rm_exp, predictions_rm_exp = Model_RMSE(features_exp[features_exp.Year != '2019'], features_exp[features_exp.Year == '2019'].drop(current_year_stats_no_player,axis=1, errors='ignore').dropna(), stats_to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PTS\n",
      "TRB\n",
      "AST\n",
      "FG%\n",
      "FT%\n",
      "STL\n",
      "BLK\n",
      "TOV\n"
     ]
    }
   ],
   "source": [
    "rmse_rm_inexp, predictions_rm_inexp = Model_RMSE(features_inexp[features_inexp.Year < '2018'], features_inexp[features_inexp.Year == '2019'].drop(current_year_stats_no_player,axis=1, errors='ignore').dropna(), stats_to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PTS\n",
      "TRB\n",
      "AST\n",
      "FG%\n",
      "FT%\n",
      "STL\n",
      "BLK\n",
      "TOV\n"
     ]
    }
   ],
   "source": [
    "rmse_rm_rookies, predictions_rm_rookies = Model_RMSE(features_rookies[features_rookies.Year < '2018'],features_rookies[features_rookies.Year == '2019'].drop(current_year_stats_no_player,axis=1, errors='ignore').dropna(), stats_to_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B. Weighted Averages** (Can only be performed for players who we have 3 years data for)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "wa_rmse = pd.DataFrame()\n",
    "stats = []\n",
    "rmses = []\n",
    "for stat in stats_to_predict:\n",
    "    players_wa = []\n",
    "    prediction_wa = []\n",
    "    for player in features_exp[features_exp.Year == '2019']['Player'].dropna():\n",
    "        pts1 = features_exp[(features_exp.Player == player)&(features_exp.Year == '2019')][stat+'1'].replace('','0').astype(float).reset_index(drop=True) * .6\n",
    "        pts2 = features_exp[(features_exp.Player == player)&(features_exp.Year == '2019')][stat+'2'].replace('','0').astype(float).reset_index(drop=True) * .3\n",
    "        pts3 = features_exp[(features_exp.Player == player)&(features_exp.Year == '2019')][stat+'3'].replace('','0').astype(float).reset_index(drop=True) * .1\n",
    "        predict_wa = pts1[0] + pts2[0] + pts3[0]\n",
    "        players_wa.append(player)\n",
    "        prediction_wa.append(predict_wa)\n",
    "    weighted_avg = pd.DataFrame()\n",
    "    weighted_avg['Player'] = players_wa\n",
    "    weighted_avg['Predict_WA'] = prediction_wa\n",
    "    weighted_avg = pd.merge(weighted_avg.dropna(), features_exp[features_exp.Year == '2019'][['Player',stat]],  how='inner', left_on=['Player'], right_on = ['Player'])\n",
    "    stats.append(stat)\n",
    "    rmses.append(RMSE(weighted_avg[stat].replace('','0').astype(float), weighted_avg['Predict_WA'].replace('','0').astype(float)))\n",
    "wa_rmse['Weighted Average'] = stats\n",
    "wa_rmse['RMSE'] = rmses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Weighted_Averages(players, stats):\n",
    "    players = players.dropna()\n",
    "    weighted_avg = pd.DataFrame()\n",
    "    df_rmse = pd.DataFrame()\n",
    "    for stat in stats:\n",
    "        players_wa = []\n",
    "        prediction_wa = []\n",
    "        for player in players['Player'].dropna():\n",
    "            s1 = players[players.Player == player][stat].replace('','0').astype(float).reset_index(drop=True) * .6\n",
    "            s2 = players[players.Player == player][stat+'1'].replace('','0').astype(float).reset_index(drop=True) * .3\n",
    "            s3 = players[players.Player == player][stat+'2'].replace('','0').astype(float).reset_index(drop=True) * .1\n",
    "            predict_wa = s1[0] + s2[0] + s3[0]\n",
    "            players_wa.append(player)\n",
    "            prediction_wa.append(predict_wa)\n",
    "        \n",
    "        weighted_avg['Player'] = players_wa\n",
    "        weighted_avg['WA_'+stat] = prediction_wa\n",
    "        #weighted_avg = pd.merge(weighted_avg.dropna(), players[['Player', stat]],  how='inner', left_on=['Player'], right_on = ['Player'])\n",
    "        \n",
    "    return weighted_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_wa = Weighted_Averages(features_exp[features_exp.Year == '2018'], stats_to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>WA_PTS</th>\n",
       "      <th>WA_TRB</th>\n",
       "      <th>WA_AST</th>\n",
       "      <th>WA_FG%</th>\n",
       "      <th>WA_FT%</th>\n",
       "      <th>WA_STL</th>\n",
       "      <th>WA_BLK</th>\n",
       "      <th>WA_TOV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vince Carter</td>\n",
       "      <td>6.30</td>\n",
       "      <td>2.73</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.3988</td>\n",
       "      <td>0.7670</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dirk Nowitzki</td>\n",
       "      <td>13.29</td>\n",
       "      <td>6.02</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.4495</td>\n",
       "      <td>0.8906</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jason Terry</td>\n",
       "      <td>3.80</td>\n",
       "      <td>1.07</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.3996</td>\n",
       "      <td>0.8636</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jamal Crawford</td>\n",
       "      <td>11.29</td>\n",
       "      <td>1.38</td>\n",
       "      <td>2.39</td>\n",
       "      <td>0.4133</td>\n",
       "      <td>0.8893</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.14</td>\n",
       "      <td>1.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tyson Chandler</td>\n",
       "      <td>7.14</td>\n",
       "      <td>9.78</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.6478</td>\n",
       "      <td>0.6566</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>Nik Stauskas</td>\n",
       "      <td>6.34</td>\n",
       "      <td>2.05</td>\n",
       "      <td>1.51</td>\n",
       "      <td>0.3913</td>\n",
       "      <td>0.7554</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>Noah Vonleh</td>\n",
       "      <td>4.62</td>\n",
       "      <td>5.43</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.4528</td>\n",
       "      <td>0.6385</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>T.J. Warren</td>\n",
       "      <td>17.18</td>\n",
       "      <td>4.90</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.4974</td>\n",
       "      <td>0.7564</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>Hassan Whiteside</td>\n",
       "      <td>14.92</td>\n",
       "      <td>12.25</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.5517</td>\n",
       "      <td>0.6752</td>\n",
       "      <td>0.69</td>\n",
       "      <td>2.02</td>\n",
       "      <td>1.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>Andrew Wiggins</td>\n",
       "      <td>19.77</td>\n",
       "      <td>4.20</td>\n",
       "      <td>2.09</td>\n",
       "      <td>0.4443</td>\n",
       "      <td>0.6899</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.54</td>\n",
       "      <td>1.93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>224 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Player  WA_PTS  WA_TRB  WA_AST  WA_FG%  WA_FT%  WA_STL  WA_BLK  \\\n",
       "0        Vince Carter    6.30    2.73    1.35  0.3988  0.7670    0.72    0.42   \n",
       "1       Dirk Nowitzki   13.29    6.02    1.59  0.4495  0.8906    0.61    0.64   \n",
       "2         Jason Terry    3.80    1.07    1.25  0.3996  0.8636    0.73    0.28   \n",
       "3      Jamal Crawford   11.29    1.38    2.39  0.4133  0.8893    0.58    0.14   \n",
       "4      Tyson Chandler    7.14    9.78    1.00  0.6478  0.6566    0.44    0.58   \n",
       "..                ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "219      Nik Stauskas    6.34    2.05    1.51  0.3913  0.7554    0.36    0.21   \n",
       "220       Noah Vonleh    4.62    5.43    0.52  0.4528  0.6385    0.39    0.33   \n",
       "221       T.J. Warren   17.18    4.90    1.20  0.4974  0.7564    1.04    0.57   \n",
       "222  Hassan Whiteside   14.92   12.25    0.85  0.5517  0.6752    0.69    2.02   \n",
       "223    Andrew Wiggins   19.77    4.20    2.09  0.4443  0.6899    1.06    0.54   \n",
       "\n",
       "     WA_TOV  \n",
       "0      0.63  \n",
       "1      0.80  \n",
       "2      0.52  \n",
       "3      1.34  \n",
       "4      1.34  \n",
       "..      ...  \n",
       "219    0.97  \n",
       "220    0.69  \n",
       "221    1.12  \n",
       "222    1.81  \n",
       "223    1.93  \n",
       "\n",
       "[224 rows x 9 columns]"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_wa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C. Average Percent Change Matrix** (Can't be used for rookies)\n",
    "\n",
    "Create Predictor Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_new = numpy.asarray(numpy.zeros((0,44), dtype=numpy.dtype('U100')))\n",
    "players_new = numpy.reshape(players_new,(0,44))\n",
    "\n",
    "for player in NBA_Stats['Player'].unique():\n",
    "    p = NBA_Stats.loc[NBA_Stats['Player']==player]\n",
    "    p2 = p[['MP','FGA','FG%','3PA','3P%','eFG%','FTA','FT%','TRB','AST','STL','BLK','TOV','PTS']].replace('','0',regex=True)\n",
    "    p2[['MP','FGA','FG%','3PA','3P%','eFG%','FTA','FT%','TRB','AST','STL','BLK','TOV','PTS']].astype(float).pct_change()\n",
    "    pcnt_change = p2[['MP','FGA','FG%','3PA','3P%','eFG%','FTA','FT%','TRB','AST','STL','BLK','TOV','PTS']].astype(float).pct_change()\n",
    "    pcnt_change = pcnt_change.rename(columns={'MP':'MP_C','FGA': 'FGA_C','FG%': 'FG%_C','3PA': '3PA_C','3P%': '3P%_C','eFG%': 'eFG%_C','FTA': 'FTA_C','FT%': 'FT%_C','TRB': 'TRB_C','AST': 'AST_C','STL': 'STL_C','BLK': 'BLK_C','TOV': 'TOV_C','PTS': 'PTS_C'})\n",
    "    p_final = pd.concat([p,pcnt_change],axis=1)\n",
    "    p_final = numpy.asarray(p_final)\n",
    "    players_new = numpy.concatenate((p_final,players_new), axis=0)\n",
    "\n",
    "players_final = pd.DataFrame(players_new)\n",
    "    \n",
    "headers2 = ['MP_C','FGA_C','FG%_C','3PA_C','3P%_C','eFG%_C','FTA_C','FT%_C','TRB_C','AST_C','STL_C','BLK_C','TOV_C','PTS_C']\n",
    "headers2 = numpy.asarray(headers2)\n",
    "headers2 = numpy.reshape(headers2,(1,14))\n",
    "\n",
    "headers_pcnt = numpy.concatenate((headers,headers2),axis=1)\n",
    "headers_pcnt = pd.DataFrame(headers_pcnt)\n",
    "\n",
    "data = pd.concat([headers_pcnt,players_final],axis=0)\n",
    "data.columns = data.iloc[0]\n",
    "data = data[1:]\n",
    "data\n",
    "\n",
    "h = ['MP','FGA','FG%','3PA','3P%','eFG%','FTA','FT%','TRB','AST','STL','BLK','TOV','PTS']\n",
    "h_c = ['MP_C','FGA_C','FG%_C','3PA_C','3P%_C','eFG%_C','FTA_C','FT%_C','TRB_C','AST_C','STL_C','BLK_C','TOV_C','PTS_C']\n",
    "\n",
    "pts_predictor = data.dropna()\n",
    "pts_predictor= pts_predictor.replace([numpy.inf, -numpy.inf], numpy.nan)\n",
    "pts_predictor = pts_predictor.dropna()\n",
    "pts_predictor['PTS_C'] = pts_predictor['PTS_C'].astype(float)\n",
    "pts_predictor.groupby('Age')['PTS_C'].mean()\n",
    "\n",
    "h = ['MP','FGA','FG%','3PA','3P%','eFG%','FTA','FT%','TRB','AST','STL','BLK','TOV','PTS']\n",
    "h_c = ['MP_C','FGA_C','FG%_C','3PA_C','3P%_C','eFG%_C','FTA_C','FT%_C','TRB_C','AST_C','STL_C','BLK_C','TOV_C','PTS_C']\n",
    "h2 = ['MP_C','FGA_','FG%_C','3PA_C','3P%_C','eFG%_C','FTA_C','FT%_C','TRB_C','AST_C','STL_C','BLK_C','TOV_C','PTS_C']\n",
    "\n",
    "predictor = pd.DataFrame()\n",
    "\n",
    "for i in h_c:\n",
    "    pts_predictor = data.dropna()\n",
    "    pts_predictor = pts_predictor.replace([numpy.inf, -numpy.inf], numpy.nan)\n",
    "    pts_predictor = pts_predictor.dropna()\n",
    "    pts_predictor[i] = pts_predictor[i].astype(float)\n",
    "    predictor[i] = pts_predictor.groupby('Age')[i].mean()\n",
    "\n",
    "predictor.index = predictor.index.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "wa_rmse = pd.DataFrame()\n",
    "stats = []\n",
    "rmses = []\n",
    "for stat in stats_to_predict:\n",
    "    players_wa = []\n",
    "    prediction_wa = []\n",
    "    for player in features_exp[features_exp.Year == '2019']['Player'].dropna():\n",
    "        pts1 = features_exp[(features_exp.Player == player)&(features_exp.Year == '2019')][stat+'1'].replace('','0').astype(float).reset_index(drop=True) * .6\n",
    "        pts2 = features_exp[(features_exp.Player == player)&(features_exp.Year == '2019')][stat+'2'].replace('','0').astype(float).reset_index(drop=True) * .3\n",
    "        pts3 = features_exp[(features_exp.Player == player)&(features_exp.Year == '2019')][stat+'3'].replace('','0').astype(float).reset_index(drop=True) * .1\n",
    "        predict_wa = pts1[0] + pts2[0] + pts3[0]\n",
    "        players_wa.append(player)\n",
    "        prediction_wa.append(predict_wa)\n",
    "    weighted_avg = pd.DataFrame()\n",
    "    weighted_avg['Player'] = players_wa\n",
    "    weighted_avg['Predict_WA'] = prediction_wa\n",
    "    weighted_avg = pd.merge(weighted_avg.dropna(), features_exp[features_exp.Year == '2019'][['Player',stat]],  how='inner', left_on=['Player'], right_on = ['Player'])\n",
    "    stats.append(stat)\n",
    "    rmses.append(RMSE(weighted_avg[stat].replace('','0').astype(float), weighted_avg['Predict_WA'].replace('','0').astype(float)))\n",
    "wa_rmse['Weighted Average'] = stats\n",
    "wa_rmse['RMSE'] = rmses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_rmse_exp = pd.DataFrame()\n",
    "stats = []\n",
    "rmses = []\n",
    "for stat in stats_to_predict:\n",
    "    df_matrix = features_exp[features_exp.Year == '2019'][['Player',stat+'1','Age']]\n",
    "    df_matrix.Age = df_matrix.Age.astype(float)\n",
    "    df_matrix = pd.merge(df_matrix.dropna(), predictor['PTS_C'], how='inner', left_on=['Age'], right_on = ['Age'])\n",
    "    df_matrix['Predict_Bracket'] = (df_matrix[stat+'1'].replace('','0').astype(float) * df_matrix['PTS_C'].replace('','0').astype(float)) + df_matrix[stat+'1'].replace('','0').astype(float)\n",
    "    df_matrix = pd.merge(df_matrix, features_exp[features_exp.Year == '2019'][['Player',stat]], how='inner',left_on=['Player'],right_on = ['Player'])\n",
    "    stats.append(stat)\n",
    "    rmses.append(RMSE(df_matrix['Predict_Bracket'].replace('','0').astype(float),df_matrix[stat].replace('','0').astype(float)))\n",
    "matrix_rmse_exp['Prediction Matrix'] = stats\n",
    "matrix_rmse_exp['RMSE'] = rmses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_rmse_inexp = pd.DataFrame()\n",
    "stats = []\n",
    "rmses = []\n",
    "for stat in stats_to_predict:\n",
    "    df_matrix = features_inexp[features_inexp.Year == '2019'][['Player',stat+'1','Age']]\n",
    "    df_matrix.Age = df_matrix.Age.astype(float)\n",
    "    df_matrix = pd.merge(df_matrix.dropna(), predictor['PTS_C'], how='inner', left_on=['Age'], right_on = ['Age'])\n",
    "    df_matrix['Predict_Bracket'] = (df_matrix[stat+'1'].replace('','0').astype(float) * df_matrix['PTS_C'].replace('','0').astype(float)) + df_matrix[stat+'1'].replace('','0').astype(float)\n",
    "    df_matrix = pd.merge(df_matrix, features_inexp[features_inexp.Year == '2019'][['Player',stat]], how='inner',left_on=['Player'],right_on = ['Player'])\n",
    "    stats.append(stat)\n",
    "    rmses.append(RMSE(df_matrix['Predict_Bracket'].replace('','0').astype(float),df_matrix[stat].replace('','0').astype(float)))\n",
    "matrix_rmse_inexp['Prediction Matrix'] = stats\n",
    "matrix_rmse_inexp['RMSE'] = rmses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prediction_Matrix(features, stats):\n",
    "    df_rmse = pd.DataFrame()\n",
    "    df_predictions = pd.DataFrame()\n",
    "    features.Age = features.Age.astype(float)\n",
    "    features['Age+1'] = features.Age + 1\n",
    "    for stat in stats:\n",
    "        df_bracket = pd.merge(features.dropna(), predictor[stat+'_C'], how='inner', left_on=['Age+1'], right_on = ['Age'])\n",
    "        df_bracket['Matrix_'+stat] = (df_bracket[stat].replace('','0').astype(float) * df_bracket[stat+'_C'].replace('','0').astype(float)) + df_bracket[stat].replace('','0').astype(float)\n",
    "        df_predictions['Player'] = df_bracket.Player\n",
    "        df_predictions['Matrix_'+stat] = df_bracket['Matrix_'+stat]\n",
    "      \n",
    "    return df_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_matrix_exp = Prediction_Matrix(features_exp[features_exp.Year == '2018'],stats_to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_matrix_inexp = Prediction_Matrix(features_inexp[features_inexp.Year == '2018'],stats_to_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.6 Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regression** - Combining All Models Performed the best in every stat for every Exp level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3+ Years Experienced Players\n",
      "PTS ['All Models Combined' 2.446780427635245]\n",
      "TRB ['All Models Combined' 1.007407302965014]\n",
      "AST ['All Models Combined' 0.7231389763960382]\n",
      "FG% ['All Models Combined' 0.03769445693404362]\n",
      "FT% ['All Models Combined' 0.07792264671667767]\n",
      "STL ['All Models Combined' 0.22053858451886937]\n",
      "BLK ['All Models Combined' 0.22650345952104287]\n",
      "TOV ['All Models Combined' 0.37102174539468985]\n",
      "\n",
      "Less than 3 years Exp Players\n",
      "PTS ['All Models Combined' 2.555172574477263]\n",
      "TRB ['All Models Combined' 1.128700178441649]\n",
      "AST ['All Models Combined' 0.727650680160697]\n",
      "FG% ['All Models Combined' 0.04208212990260983]\n",
      "FT% ['All Models Combined' 0.07829242970910885]\n",
      "STL ['All Models Combined' 0.2626737494719895]\n",
      "BLK ['All Models Combined' 0.2725032169090972]\n",
      "TOV ['All Models Combined' 0.4104910951571951]\n",
      "\n",
      "Rookies\n",
      "PTS ['All Models Combined' 3.7335920351072227]\n",
      "TRB ['All Models Combined' 1.4719133027422913]\n",
      "AST ['All Models Combined' 0.9808967610626652]\n",
      "FG% ['All Models Combined' 0.0550556990043444]\n",
      "FT% ['All Models Combined' 0.09776862429344822]\n",
      "STL ['All Models Combined' 0.27414889587918895]\n",
      "BLK ['All Models Combined' 0.257784871100209]\n",
      "TOV ['All Models Combined' 0.6490363470100777]\n"
     ]
    }
   ],
   "source": [
    "print('3+ Years Experienced Players')\n",
    "for stat in stats_to_predict:\n",
    "    print(stat, rmse_rm_exp[['Model',stat]].min().values)\n",
    "print('')\n",
    "print('Less than 3 years Exp Players')\n",
    "for stat in stats_to_predict:\n",
    "    print(stat, rmse_rm_inexp[['Model',stat]].min().values)\n",
    "print('')\n",
    "print('Rookies')\n",
    "for stat in stats_to_predict:\n",
    "    print(stat, rmse_rm_rookies[['Model',stat]].min().values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Weighted Average** - Only applicable to players with 3+ Years Exp\n",
    "\n",
    "Performed pretty well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_b87db2aa_0d9f_11eb_8e5e_645aedea38eb\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >Weighted Average</th>        <th class=\"col_heading level0 col1\" >RMSE</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_b87db2aa_0d9f_11eb_8e5e_645aedea38ebrow0_col0\" class=\"data row0 col0\" >PTS</td>\n",
       "                        <td id=\"T_b87db2aa_0d9f_11eb_8e5e_645aedea38ebrow0_col1\" class=\"data row0 col1\" >2.910131</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_b87db2aa_0d9f_11eb_8e5e_645aedea38ebrow1_col0\" class=\"data row1 col0\" >TRB</td>\n",
       "                        <td id=\"T_b87db2aa_0d9f_11eb_8e5e_645aedea38ebrow1_col1\" class=\"data row1 col1\" >1.220119</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_b87db2aa_0d9f_11eb_8e5e_645aedea38ebrow2_col0\" class=\"data row2 col0\" >AST</td>\n",
       "                        <td id=\"T_b87db2aa_0d9f_11eb_8e5e_645aedea38ebrow2_col1\" class=\"data row2 col1\" >0.821611</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_b87db2aa_0d9f_11eb_8e5e_645aedea38ebrow3_col0\" class=\"data row3 col0\" >FG%</td>\n",
       "                        <td id=\"T_b87db2aa_0d9f_11eb_8e5e_645aedea38ebrow3_col1\" class=\"data row3 col1\" >0.038088</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_b87db2aa_0d9f_11eb_8e5e_645aedea38ebrow4_col0\" class=\"data row4 col0\" >FT%</td>\n",
       "                        <td id=\"T_b87db2aa_0d9f_11eb_8e5e_645aedea38ebrow4_col1\" class=\"data row4 col1\" >0.068128</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_b87db2aa_0d9f_11eb_8e5e_645aedea38ebrow5_col0\" class=\"data row5 col0\" >STL</td>\n",
       "                        <td id=\"T_b87db2aa_0d9f_11eb_8e5e_645aedea38ebrow5_col1\" class=\"data row5 col1\" >0.232049</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_b87db2aa_0d9f_11eb_8e5e_645aedea38ebrow6_col0\" class=\"data row6 col0\" >BLK</td>\n",
       "                        <td id=\"T_b87db2aa_0d9f_11eb_8e5e_645aedea38ebrow6_col1\" class=\"data row6 col1\" >0.210426</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_b87db2aa_0d9f_11eb_8e5e_645aedea38ebrow7_col0\" class=\"data row7 col0\" >TOV</td>\n",
       "                        <td id=\"T_b87db2aa_0d9f_11eb_8e5e_645aedea38ebrow7_col1\" class=\"data row7 col1\" >0.407224</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fb859788110>"
      ]
     },
     "execution_count": 538,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wa_rmse.style.hide_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Average Percent Change Matrix** - Can't Be applied to Rookies\n",
    "\n",
    "Performed ok at the 3+year level, not as great with the < 3year exp level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_b91dce98_0d9f_11eb_8e5e_645aedea38eb\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >Prediction Matrix</th>        <th class=\"col_heading level0 col1\" >RMSE</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_b91dce98_0d9f_11eb_8e5e_645aedea38ebrow0_col0\" class=\"data row0 col0\" >PTS</td>\n",
       "                        <td id=\"T_b91dce98_0d9f_11eb_8e5e_645aedea38ebrow0_col1\" class=\"data row0 col1\" >3.116014</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_b91dce98_0d9f_11eb_8e5e_645aedea38ebrow1_col0\" class=\"data row1 col0\" >TRB</td>\n",
       "                        <td id=\"T_b91dce98_0d9f_11eb_8e5e_645aedea38ebrow1_col1\" class=\"data row1 col1\" >1.330742</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_b91dce98_0d9f_11eb_8e5e_645aedea38ebrow2_col0\" class=\"data row2 col0\" >AST</td>\n",
       "                        <td id=\"T_b91dce98_0d9f_11eb_8e5e_645aedea38ebrow2_col1\" class=\"data row2 col1\" >0.885313</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_b91dce98_0d9f_11eb_8e5e_645aedea38ebrow3_col0\" class=\"data row3 col0\" >FG%</td>\n",
       "                        <td id=\"T_b91dce98_0d9f_11eb_8e5e_645aedea38ebrow3_col1\" class=\"data row3 col1\" >0.087058</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_b91dce98_0d9f_11eb_8e5e_645aedea38ebrow4_col0\" class=\"data row4 col0\" >FT%</td>\n",
       "                        <td id=\"T_b91dce98_0d9f_11eb_8e5e_645aedea38ebrow4_col1\" class=\"data row4 col1\" >0.150649</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_b91dce98_0d9f_11eb_8e5e_645aedea38ebrow5_col0\" class=\"data row5 col0\" >STL</td>\n",
       "                        <td id=\"T_b91dce98_0d9f_11eb_8e5e_645aedea38ebrow5_col1\" class=\"data row5 col1\" >0.286741</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_b91dce98_0d9f_11eb_8e5e_645aedea38ebrow6_col0\" class=\"data row6 col0\" >BLK</td>\n",
       "                        <td id=\"T_b91dce98_0d9f_11eb_8e5e_645aedea38ebrow6_col1\" class=\"data row6 col1\" >0.234804</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_b91dce98_0d9f_11eb_8e5e_645aedea38ebrow7_col0\" class=\"data row7 col0\" >TOV</td>\n",
       "                        <td id=\"T_b91dce98_0d9f_11eb_8e5e_645aedea38ebrow7_col1\" class=\"data row7 col1\" >0.459406</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fb80f919150>"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_rmse_exp.style.hide_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_b98da646_0d9f_11eb_8e5e_645aedea38eb\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >Prediction Matrix</th>        <th class=\"col_heading level0 col1\" >RMSE</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_b98da646_0d9f_11eb_8e5e_645aedea38ebrow0_col0\" class=\"data row0 col0\" >PTS</td>\n",
       "                        <td id=\"T_b98da646_0d9f_11eb_8e5e_645aedea38ebrow0_col1\" class=\"data row0 col1\" >3.519914</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_b98da646_0d9f_11eb_8e5e_645aedea38ebrow1_col0\" class=\"data row1 col0\" >TRB</td>\n",
       "                        <td id=\"T_b98da646_0d9f_11eb_8e5e_645aedea38ebrow1_col1\" class=\"data row1 col1\" >1.516457</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_b98da646_0d9f_11eb_8e5e_645aedea38ebrow2_col0\" class=\"data row2 col0\" >AST</td>\n",
       "                        <td id=\"T_b98da646_0d9f_11eb_8e5e_645aedea38ebrow2_col1\" class=\"data row2 col1\" >0.935671</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_b98da646_0d9f_11eb_8e5e_645aedea38ebrow3_col0\" class=\"data row3 col0\" >FG%</td>\n",
       "                        <td id=\"T_b98da646_0d9f_11eb_8e5e_645aedea38ebrow3_col1\" class=\"data row3 col1\" >0.123759</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_b98da646_0d9f_11eb_8e5e_645aedea38ebrow4_col0\" class=\"data row4 col0\" >FT%</td>\n",
       "                        <td id=\"T_b98da646_0d9f_11eb_8e5e_645aedea38ebrow4_col1\" class=\"data row4 col1\" >0.220964</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_b98da646_0d9f_11eb_8e5e_645aedea38ebrow5_col0\" class=\"data row5 col0\" >STL</td>\n",
       "                        <td id=\"T_b98da646_0d9f_11eb_8e5e_645aedea38ebrow5_col1\" class=\"data row5 col1\" >0.330935</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_b98da646_0d9f_11eb_8e5e_645aedea38ebrow6_col0\" class=\"data row6 col0\" >BLK</td>\n",
       "                        <td id=\"T_b98da646_0d9f_11eb_8e5e_645aedea38ebrow6_col1\" class=\"data row6 col1\" >0.262087</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_b98da646_0d9f_11eb_8e5e_645aedea38ebrow7_col0\" class=\"data row7 col0\" >TOV</td>\n",
       "                        <td id=\"T_b98da646_0d9f_11eb_8e5e_645aedea38ebrow7_col1\" class=\"data row7 col1\" >0.540649</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fb85ba1db50>"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_rmse_inexp.style.hide_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Combining All Methods**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>WA_PTS</th>\n",
       "      <th>PTS</th>\n",
       "      <th>WA_TRB</th>\n",
       "      <th>TRB</th>\n",
       "      <th>WA_AST</th>\n",
       "      <th>AST</th>\n",
       "      <th>WA_FG%</th>\n",
       "      <th>FG%</th>\n",
       "      <th>WA_FT%</th>\n",
       "      <th>FT%</th>\n",
       "      <th>WA_STL</th>\n",
       "      <th>STL</th>\n",
       "      <th>WA_BLK</th>\n",
       "      <th>BLK</th>\n",
       "      <th>WA_TOV</th>\n",
       "      <th>TOV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vince Carter</td>\n",
       "      <td>6.30</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.73</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.35</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.3988</td>\n",
       "      <td>.403</td>\n",
       "      <td>0.7670</td>\n",
       "      <td>.757</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dirk Nowitzki</td>\n",
       "      <td>13.29</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.02</td>\n",
       "      <td>5.7</td>\n",
       "      <td>1.59</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4495</td>\n",
       "      <td>.456</td>\n",
       "      <td>0.8906</td>\n",
       "      <td>.898</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jason Terry</td>\n",
       "      <td>3.80</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.3996</td>\n",
       "      <td>.383</td>\n",
       "      <td>0.8636</td>\n",
       "      <td>.889</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jamal Crawford</td>\n",
       "      <td>11.29</td>\n",
       "      <td>10.3</td>\n",
       "      <td>1.38</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.39</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.4133</td>\n",
       "      <td>.415</td>\n",
       "      <td>0.8893</td>\n",
       "      <td>.903</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.34</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tyson Chandler</td>\n",
       "      <td>7.14</td>\n",
       "      <td>6.5</td>\n",
       "      <td>9.78</td>\n",
       "      <td>9.1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.6478</td>\n",
       "      <td>.647</td>\n",
       "      <td>0.6566</td>\n",
       "      <td>.624</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.34</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>Nik Stauskas</td>\n",
       "      <td>6.34</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2.05</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.51</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3913</td>\n",
       "      <td>.390</td>\n",
       "      <td>0.7554</td>\n",
       "      <td>.724</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>Noah Vonleh</td>\n",
       "      <td>4.62</td>\n",
       "      <td>4.9</td>\n",
       "      <td>5.43</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4528</td>\n",
       "      <td>.444</td>\n",
       "      <td>0.6385</td>\n",
       "      <td>.621</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>T.J. Warren</td>\n",
       "      <td>17.18</td>\n",
       "      <td>19.6</td>\n",
       "      <td>4.90</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.4974</td>\n",
       "      <td>.498</td>\n",
       "      <td>0.7564</td>\n",
       "      <td>.757</td>\n",
       "      <td>1.04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.12</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>Hassan Whiteside</td>\n",
       "      <td>14.92</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.25</td>\n",
       "      <td>11.4</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5517</td>\n",
       "      <td>.540</td>\n",
       "      <td>0.6752</td>\n",
       "      <td>.703</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.02</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.81</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>Andrew Wiggins</td>\n",
       "      <td>19.77</td>\n",
       "      <td>17.7</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2.09</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4443</td>\n",
       "      <td>.438</td>\n",
       "      <td>0.6899</td>\n",
       "      <td>.643</td>\n",
       "      <td>1.06</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.93</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>224 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Player  WA_PTS   PTS  WA_TRB   TRB  WA_AST  AST  WA_FG%   FG%  \\\n",
       "0        Vince Carter    6.30   5.4    2.73   2.6    1.35  1.2  0.3988  .403   \n",
       "1       Dirk Nowitzki   13.29  12.0    6.02   5.7    1.59  1.6  0.4495  .456   \n",
       "2         Jason Terry    3.80   3.3    1.07   0.9    1.25  1.2  0.3996  .383   \n",
       "3      Jamal Crawford   11.29  10.3    1.38   1.2    2.39  2.3  0.4133  .415   \n",
       "4      Tyson Chandler    7.14   6.5    9.78   9.1    1.00  1.2  0.6478  .647   \n",
       "..                ...     ...   ...     ...   ...     ...  ...     ...   ...   \n",
       "219      Nik Stauskas    6.34   4.4    2.05   1.6    1.51  1.0  0.3913  .390   \n",
       "220       Noah Vonleh    4.62   4.9    5.43   5.8    0.52  0.6  0.4528  .444   \n",
       "221       T.J. Warren   17.18  19.6    4.90   5.1    1.20  1.3  0.4974  .498   \n",
       "222  Hassan Whiteside   14.92  14.0   12.25  11.4    0.85  1.0  0.5517  .540   \n",
       "223    Andrew Wiggins   19.77  17.7    4.20   4.4    2.09  2.0  0.4443  .438   \n",
       "\n",
       "     WA_FT%   FT%  WA_STL  STL  WA_BLK  BLK  WA_TOV  TOV  \n",
       "0    0.7670  .757    0.72  0.7    0.42  0.4    0.63  0.6  \n",
       "1    0.8906  .898    0.61  0.6    0.64  0.6    0.80  0.7  \n",
       "2    0.8636  .889    0.73  0.8    0.28  0.3    0.52  0.5  \n",
       "3    0.8893  .903    0.58  0.5    0.14  0.1    1.34  1.2  \n",
       "4    0.6566  .624    0.44  0.3    0.58  0.6    1.34  1.3  \n",
       "..      ...   ...     ...  ...     ...  ...     ...  ...  \n",
       "219  0.7554  .724    0.36  0.2    0.21  0.1    0.97  0.6  \n",
       "220  0.6385  .621    0.39  0.4    0.33  0.3    0.69  0.6  \n",
       "221  0.7564  .757    1.04  1.0    0.57  0.6    1.12  1.3  \n",
       "222  0.6752  .703    0.69  0.7    2.02  1.7    1.81  1.7  \n",
       "223  0.6899  .643    1.06  1.1    0.54  0.6    1.93  1.7  \n",
       "\n",
       "[224 rows x 17 columns]"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_rm_exp\n",
    "predictions_rm_inexp\n",
    "predictions_rm_rookies\n",
    "\n",
    "predictions_matrix_exp\n",
    "predictions_matrix_inexp\n",
    "\n",
    "predictions_wa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_methods_exp = pd.DataFrame()\n",
    "df_all_methods_exp = pd.merge(predictions_rm_exp, predictions_matrix_exp, how='inner', left_on=['Player'],right_on=['Player'])\n",
    "df_all_methods_exp = pd.merge(df_all_methods_exp, predictions_wa, how='inner', left_on=['Player'],right_on=['Player'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_exp = pd.DataFrame()\n",
    "df_combined_exp['Player'] = df_all_methods_exp.Player\n",
    "for stat in stats_to_predict:\n",
    "    combined_exp_list = []\n",
    "    for i in range(len(df_all_methods_exp['Player'])):\n",
    "        combined_prediction = (df_all_methods_exp['Regression_PTS'].iloc[i] + df_all_methods_exp['Matrix_PTS'].iloc[i] + df_all_methods_exp['WA_PTS'].iloc[i])/3\n",
    "        combined_exp_list.append(combined_prediction)\n",
    "    df_combined_exp['Combined_'+stat] = combined_exp_list\n",
    "    \n",
    "df_combined_exp = pd.merge(df_combined_exp, features_exp[features_exp.Year=='2019'][['Player','PTS','TRB','AST','MP','FG%','FT%','STL','BLK','TOV']],how='inner',left_on=['Player'],right_on=['Player'])\n",
    "df_all_methods_exp = pd.merge(df_all_methods_exp, df_combined_exp,how='inner',left_on=['Player'],right_on=['Player'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluating the optimal Model Combination for each stat for Exp Players**\n",
    "\n",
    "- All Methods Weighted: PTS, AST, BLK\n",
    "- Regression: TRB, MP, FG%, FT%, STL, TOV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PTS All Weighted:  2.3999845248390903\n",
      "TRB Regression:  1.006882276776232\n",
      "AST All Weighted:  0.715333460561931\n",
      "FG% All Weighted:  0.03280103828458025\n",
      "FT% Regression:  0.06678071094722716\n",
      "STL Regression:  0.20331152267794347\n",
      "BLK All Weighted:  0.18489434841197105\n",
      "TOV Regression:  0.3566945206583794\n"
     ]
    }
   ],
   "source": [
    "reg_weight = .7\n",
    "matrix_weight = .15\n",
    "wa_weight = .15\n",
    "\n",
    "for stat in stats_to_predict:\n",
    "    all_methods = RMSE(df_all_methods_exp['Combined_'+stat], df_all_methods_exp[stat])\n",
    "    regression = RMSE(df_all_methods_exp['Regression_'+stat], df_all_methods_exp[stat])\n",
    "    matrix = RMSE(df_all_methods_exp['Matrix_'+stat], df_all_methods_exp[stat])\n",
    "    wa = RMSE(df_all_methods_exp['WA_'+stat], df_all_methods_exp[stat])\n",
    "    regression_wa = RMSE(((df_all_methods_exp['Regression_'+stat] + df_all_methods_exp['WA_'+stat])/2), df_all_methods_exp[stat])\n",
    "    regression_matrix = RMSE(((df_all_methods_exp['Regression_'+stat] + df_all_methods_exp['Matrix_'+stat])/2), df_all_methods_exp[stat])\n",
    "    all_methods_weighted = RMSE((((df_all_methods_exp['Regression_'+stat] * reg_weight) + (df_all_methods_exp['Matrix_'+stat] * matrix_weight) + (df_all_methods_exp['WA_'+stat] * wa_weight) )), df_all_methods_exp[stat])\n",
    "    min_rmse = min(all_methods, regression, matrix, wa, regression_wa, regression_matrix, all_methods_weighted)\n",
    "    if min_rmse == all_methods:\n",
    "        print(stat, 'All Methods: ', all_methods)\n",
    "    elif min_rmse == regression:\n",
    "        print(stat, 'Regression: ', regression)\n",
    "    elif min_rmse == matrix:\n",
    "        print(stat,'Matrix: ', matrix)\n",
    "    elif min_rmse == wa:\n",
    "        print(stat,'Weighted Average: ', wa)\n",
    "    elif min_rmse == regression_wa:\n",
    "        print(stat,'Regression and Weighted Avg: ', regression_wa)\n",
    "    elif min_rmse == regression_matrix:\n",
    "        print(stat,'Regression and Matrix: ', regression_matrix)\n",
    "    elif min_rmse == all_methods_weighted:\n",
    "        print(stat,'All Weighted: ', all_methods_weighted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluating the optimal Model Combination for each stat for inexperienced Players**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_methods_inexp = pd.merge(predictions_rm_inexp, predictions_matrix_inexp, how='inner',left_on=['Player'],right_on=['Player'])\n",
    "df_all_methods_inexp = pd.merge(df_all_methods_inexp, features_exp[features_exp.Year=='2019'][['Player','PTS','TRB','AST','MP','FG%','FT%','STL','BLK','TOV']],  how='inner',left_on=['Player'],right_on=['Player'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PTS Regression:  2.765880903795581\n",
      "TRB Regression:  1.1346268449031354\n",
      "AST Regression:  0.5112605632025802\n",
      "FG% All Methods:  0.046606917918684605\n",
      "FT% Regression:  0.08139428262890944\n",
      "STL Regression:  0.2526232994203638\n",
      "BLK Regression:  0.18189031479795545\n",
      "TOV Regression:  0.30296212925877186\n"
     ]
    }
   ],
   "source": [
    "reg_weight = .75\n",
    "matrix_weight = .25\n",
    "min_rmse_sum = 0\n",
    "\n",
    "for stat in stats_to_predict:\n",
    "    regression_matrix = RMSE(((df_all_methods_inexp['Regression_'+stat] + df_all_methods_inexp['Matrix_'+stat])/2), df_all_methods_inexp[stat])\n",
    "    regression = RMSE(df_all_methods_inexp['Regression_'+stat], df_all_methods_inexp[stat])    \n",
    "    matrix = RMSE(df_all_methods_inexp['Matrix_'+stat], df_all_methods_inexp[stat])\n",
    "    all_methods_weighted = RMSE((((df_all_methods_inexp['Regression_'+stat] * reg_weight) + (df_all_methods_inexp['Matrix_'+stat] * matrix_weight))), df_all_methods_inexp[stat])\n",
    "  \n",
    "    min_rmse = min(regression_matrix, regression, matrix, all_methods_weighted)\n",
    "    min_rmse_sum += min_rmse\n",
    "    if min_rmse == regression_matrix:\n",
    "        print(stat, 'All Methods: ', regression_matrix)\n",
    "    elif min_rmse == regression:\n",
    "        print(stat, 'Regression: ', regression)\n",
    "    elif min_rmse == matrix:\n",
    "        print(stat,'Matrix: ', matrix)\n",
    "    elif min_rmse == all_methods_weighted:\n",
    "        print(stat,'All Weighted: ', all_methods_weighted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To summarize, we'll use the cominbation below to predict NBA player 2020 stats:**\n",
    "\n",
    "1. Experienced Players (3 years+ exp)\n",
    "    - All Weighted (80-10-10): PTS, AST, BLK\n",
    "    - Regression: TRB, FT%, TOV, MP, FG%, STL\n",
    "    - Regression and WA: \n",
    "2. Inexperienced Players (less than 3 years exp)\n",
    "    - All Weighted: FG%\n",
    "    - Regression: Rest\n",
    "3. Rookies\n",
    "    - Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Call Functions To Train Models and Process Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experienced Player Predictions**\n",
    "\n",
    "Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_rm_2020_exp, predict_rm_2020_exp = Model_RMSE(features_exp, features_exp[features_exp.Year == '2019'][['Player','Age', 'G', 'GS', 'MP', 'PTS', 'FGA', 'FG%', '3PA', '3P%',\n",
    "       'eFG%', 'FTA', 'FT%', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'MP1',\n",
    "       'PTS1', 'FGA1', 'FG%1', '3PA1', '3P%1', 'eFG%1', 'FTA1', 'FT%1', 'TRB1',\n",
    "       'AST1', 'STL1', 'BLK1', 'TOV1', 'MP2', 'PTS2', 'FGA2', 'FG%2', '3PA2',\n",
    "       '3P%2', 'eFG%2', 'FTA2', 'FT%2', 'TRB2', 'AST2', 'STL2', 'BLK2', 'TOV2',\n",
    "       'C', 'PF', 'PG', 'SF', 'SG', 'Traded', 'Starter', 'Years_Pro']].dropna(), stats_to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_rm_2020_exp2, predict_rm_2020_exp2 = Model_RMSE(features_exp, features_exp[features_exp.Year == '2019'][['Player','Age', 'G', 'GS', 'MP', 'PTS', 'FGA', 'FG%', '3PA', '3P%',\n",
    "       'eFG%', 'FTA', 'FT%', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'MP1',\n",
    "       'PTS1', 'FGA1', 'FG%1', '3PA1', '3P%1', 'eFG%1', 'FTA1', 'FT%1', 'TRB1',\n",
    "       'AST1', 'STL1', 'BLK1', 'TOV1', 'MP2', 'PTS2', 'FGA2', 'FG%2', '3PA2',\n",
    "       '3P%2', 'eFG%2', 'FTA2', 'FT%2', 'TRB2', 'AST2', 'STL2', 'BLK2', 'TOV2',\n",
    "       'C', 'PF', 'PG', 'SF', 'SG', 'Traded', 'Starter', 'Years_Pro']].dropna(), stats_to_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_matrix_2020_exp = Prediction_Matrix(features_exp[features_exp.Year == '2019'],stats_to_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weighted Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_2020_wa = Weighted_Averages(features_exp[features_exp.Year == '2019'], stats_to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_2020_exp = pd.merge(predict_rm_2020_exp2, predictions_2020_wa[['Player','WA_PTS','WA_AST','WA_BLK']], how='inner',left_on=['Player'],right_on=['Player'])\n",
    "predictions_2020_exp = pd.merge(predictions_2020_exp, predict_matrix_2020_exp[['Player','Matrix_PTS','Matrix_AST','Matrix_BLK']], how='inner',left_on=['Player'],right_on=['Player'])\n",
    "predictions_2020_exp['Predict_PTS'] = (predictions_2020_exp.Regression_PTS * .8) + (predictions_2020_exp.WA_PTS * .1) + (predictions_2020_exp.Matrix_PTS *.1)\n",
    "predictions_2020_exp['Predict_AST'] = (predictions_2020_exp.Regression_AST * .8) + (predictions_2020_exp.WA_AST * .1) + (predictions_2020_exp.Matrix_AST *.1)\n",
    "predictions_2020_exp['Predict_BLK'] = (predictions_2020_exp.Regression_BLK * .8) + (predictions_2020_exp.WA_BLK * .1) + (predictions_2020_exp.Matrix_BLK *.1)\n",
    "predictions_2020_exp = predictions_2020_exp.rename(columns={\"Regression_MP\":\"Predict_MP\",\"Regression_FT%\":\"Predict_FT%\",\"Regression_TRB\":\"Predict_TRB\",\"Regression_STL\":\"Predict_STL\",\"Regression_TOV\":\"Predict_TOV\",\"Regression_FG%\":\"Predict_FG%\"})\n",
    "predictions_2020_exp = predictions_2020_exp[['Player','Predict_PTS','Predict_TRB','Predict_AST','Predict_MP','Predict_FG%','Predict_FT%','Predict_STL','Predict_BLK','Predict_TOV']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inexperienced Players Predictions**\n",
    "\n",
    "Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_rm_2020_inexp, predict_rm_2020_inexp = Model_RMSE(features_inexp, features_inexp[features_inexp.Year == '2019'][['Player', 'Age', 'G', 'GS', 'MP', 'PTS', 'FGA', 'FG%', '3PA',\n",
    "       '3P%', 'eFG%', 'FTA', 'FT%', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'C', 'PF', 'PG', 'SF', 'SG', 'Traded', 'Starter', 'Years_Pro']].dropna(), stats_to_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_matrix_2020_inexp = Prediction_Matrix(features_inexp[features_inexp.Year == '2019'],stats_to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_2020_inexp = pd.merge(predict_rm_2020_inexp, predict_matrix_2020_inexp[['Player','Matrix_FG%']], how='inner',left_on=['Player'],right_on=['Player'])\n",
    "predictions_2020_inexp['Predict_FG%'] = (predictions_2020_inexp['Matrix_FG%'] + predictions_2020_inexp['Regression_FG%']) / 2\n",
    "predictions_2020_inexp = predictions_2020_inexp.drop(['Matrix_FG%','Regression_FG%'],axis=1)\n",
    "predictions_2020_inexp = predictions_2020_inexp.rename(columns={\"Regression_MP\":\"Predict_MP\",\"Regression_PTS\":\"Predict_PTS\",\"Regression_FT%\":\"Predict_FT%\",\"Regression_TRB\":\"Predict_TRB\",\"Regression_AST\":\"Predict_AST\",\"Regression_STL\":\"Predict_STL\",\"Regression_BLK\":\"Predict_BLK\",\"Regression_TOV\":\"Predict_TOV\",\"Regression_FG%\":\"Predict_FG%\"})\n",
    "predictions_2020_inexp = predictions_2020_inexp[['Player','Predict_PTS','Predict_TRB','Predict_AST','Predict_FG%','Predict_FT%','Predict_STL','Predict_BLK','Predict_TOV']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rookies Predictions**\n",
    "\n",
    "Webscrape 2020 NBA Rookies college stats and Preprocess data (We only pulled for 2019 when building our model in order to exclude bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WEBSCRAPE LIST OF ALL 2020 NBA ROOKIES\n",
    "\n",
    "players_list_agg = []\n",
    "holder = 0\n",
    "\n",
    "url = 'https://www.basketball-reference.com/leagues/NBA_2020_rookies.html'\n",
    "headers= {'User-Agent': 'Mozilla/5.0'}\n",
    "response = requests.get(url, headers = headers)\n",
    "response.status_code\n",
    "response.content\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "stat_table = soup.find_all('table', class_ = 'stats_table')\n",
    "stat_table = stat_table[0]\n",
    "\n",
    "players_list = []\n",
    "for row in stat_table.find_all('tr'):\n",
    "    for cell in row.find_all('td'):\n",
    "        players_list_agg.append(cell.text)\n",
    "        players_list.append(cell.text)\n",
    "\n",
    "rookies_list = []\n",
    "ctr = 0\n",
    "for i in range(int(len(players_list) / 27)):\n",
    "    rookies_list.append(players_list[ctr])\n",
    "    ctr+=27\n",
    "    \n",
    "NBA_rookies = pd.DataFrame()\n",
    "NBA_rookies['Player'] = rookies_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WEBSCRAPE ROOKIES\n",
    "\n",
    "rookies_agg = numpy.asarray(numpy.zeros((0,29), dtype=numpy.dtype('U100')))\n",
    "rookies_agg = numpy.reshape(rookies_agg,(0,29))\n",
    "\n",
    "for player in NBA_rookies.Player:#.replace(' ','-',regex=True):\n",
    "    player_search = player.replace('.','')\n",
    "    player_search = player_search.replace(' ','-')\n",
    "    url = 'https://www.sports-reference.com/cbb/players/'+player_search.lower()+'-1.html'\n",
    "    hdrs= {'User-Agent': 'Mozilla/5.0'}\n",
    "    response = requests.get(url, headers = hdrs)\n",
    "    response.status_code\n",
    "    response.content\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        #soup.findAll('tr',limit=2)\n",
    "        stat_table = soup.find_all('table', class_ = 'stats_table')\n",
    "        stat_table = stat_table[0]\n",
    "        stats = []\n",
    "        for row in stat_table.find_all('tr'):\n",
    "            for cell in row.find_all('td'):\n",
    "                stats.append(cell.text)\n",
    "        stats = stats[-28:]\n",
    "        stats.insert(0,player)\n",
    "        stats = numpy.asarray(stats[0:29])\n",
    "        stats = numpy.asarray(stats)\n",
    "        stats = numpy.reshape(stats,(1,29))\n",
    "        rookies_agg = numpy.concatenate((rookies_agg,stats),0)\n",
    "\n",
    "        headers_list = [th.getText() for th in soup.findAll('tr',limit=2)[0].findAll('th')]\n",
    "        headers_list.insert(1,'Player')\n",
    "headers_list = headers_list[1:30]\n",
    "headers_list = numpy.asarray(headers_list)\n",
    "headers_list = numpy.reshape(headers_list,(1,29))\n",
    "player_stats = numpy.concatenate((headers_list, rookies_agg),0)\n",
    "rookies2020 = pd.DataFrame(player_stats)\n",
    "rookies2020.columns = rookies2020.loc[0]\n",
    "rookies2020 = rookies2020.loc[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "rookies2020['G'] = rookies2020['G'].apply(lambda x: np.nan if x.isnumeric() == False else x)\n",
    "rookies2020['2P'] = rookies2020['2P'].apply(lambda x: np.nan if x.isalpha() == True else x)\n",
    "rookies2020 = rookies2020.replace('','0').dropna()\n",
    "rookies2020_features = rookies2020[['Player', 'MP', 'FG%', 'FT%', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PTS', 'SOS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_rm_2020_rookies, predictions_rm_2020_rookies = Model_RMSE(features_rookies,rookies2020_features.dropna(), stats_to_predict)\n",
    "predictions_rm_2020_rookies = predictions_rm_2020_rookies.rename(columns={\"Regression_MP\":\"Predict_MP\",\"Regression_PTS\":\"Predict_PTS\",\"Regression_FT%\":\"Predict_FT%\",\"Regression_TRB\":\"Predict_TRB\",\"Regression_AST\":\"Predict_AST\",\"Regression_STL\":\"Predict_STL\",\"Regression_BLK\":\"Predict_BLK\",\"Regression_TOV\":\"Predict_TOV\",\"Regression_FG%\":\"Predict_FG%\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Combined Experienced, Inexperienced, and Rookie Player Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_2020_predictions = pd.concat([predictions_2020_exp, predictions_2020_inexp, predictions_rm_2020_rookies])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Compare Predictions v Actual\n",
    "\n",
    "# 3.1 Pull Latest Year Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(651, 30)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_to_loop = ['2020']\n",
    "years = []\n",
    "players_list_agg = []\n",
    "holder = 0\n",
    "\n",
    "for year in year_to_loop:\n",
    "    url = 'https://www.basketball-reference.com/leagues/NBA_'+year+'_per_game.html'\n",
    "    headers= {'User-Agent': 'Mozilla/5.0'}\n",
    "    response = requests.get(url, headers = headers)\n",
    "    response.status_code\n",
    "    response.content\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    stat_table = soup.find_all('table', class_ = 'stats_table')\n",
    "    stat_table = stat_table[0]\n",
    "\n",
    "    players_list = []\n",
    "    for row in stat_table.find_all('tr'):\n",
    "        for cell in row.find_all('td'):\n",
    "            players_list_agg.append(cell.text)\n",
    "            players_list.append(cell.text)\n",
    "    \n",
    "    holder += len(players_list)\n",
    "    headers_list = [th.getText() for th in soup.findAll('tr',limit=2)[0].findAll('th')]\n",
    "    for i in range(int((int(len(players_list)))/(int(len(headers_list)-1)))):\n",
    "        years.append(year)\n",
    "    \n",
    "headers_list = [th.getText() for th in soup.findAll('tr',limit=2)[0].findAll('th')]\n",
    "headers_list = headers_list[1:]\n",
    "headers_list.insert(0,'Year')\n",
    "\n",
    "players = numpy.asarray(players_list_agg)\n",
    "players = numpy.reshape(players,( int( len(players_list_agg) / (len(headers_list)-1) ) , int( len(headers_list)-1 ) ))\n",
    "\n",
    "years = numpy.asarray(years)\n",
    "years = numpy.reshape(years,( int( len(years) ), 1 ))\n",
    "\n",
    "headers = numpy.asarray(headers_list)\n",
    "headers = numpy.reshape(headers,(1,len(headers_list)))\n",
    "\n",
    "players_years = numpy.concatenate((years,players),1)\n",
    "players_headers = numpy.concatenate((headers, players_years), 0)\n",
    "\n",
    "NBA_2020_Stats = pd.DataFrame(players_headers)\n",
    "NBA_2020_Stats.columns = NBA_2020_Stats.iloc[0]\n",
    "NBA_2020_Stats = NBA_2020_Stats[1:]\n",
    "\n",
    "NBA_2020_Stats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(529, 30)"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for player, year in NBA_2020_Stats.loc[NBA_2020_Stats['Tm']=='TOT'][['Player','Year']].itertuples(index=False):\n",
    "    NBA_2020_Stats = NBA_2020_Stats.drop(NBA_2020_Stats[(NBA_2020_Stats['Player'] == player) & (NBA_2020_Stats['Tm'] != 'TOT')& (NBA_2020_Stats['Year'] == year)].index)\n",
    "\n",
    "NBA_2020_Stats.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 Compare Predictions v Actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = pd.merge(final_2020_predictions, NBA_2020_Stats, how = 'inner',left_on=['Player'],right_on=['Player'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison[['FG%','FT%','PTS']] = comparison[['FG%','FT%','PTS']].replace('','0').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction vs Actual RMSEs\n",
      "\n",
      "PTS 3.3142037251758953\n",
      "TRB 1.2793870029168923\n",
      "AST 0.8616043787425645\n",
      "FG% 0.08408368304164103\n",
      "FT% 0.19186101337521266\n",
      "STL 0.2762493560527606\n",
      "BLK 0.23613478167802757\n",
      "TOV 0.43964626783052607\n"
     ]
    }
   ],
   "source": [
    "print('Prediction vs Actual RMSEs')\n",
    "print('')\n",
    "for stat in stats_to_predict:\n",
    "    print(stat, RMSE(comparison['Predict_' + stat], comparison[stat]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus: Model Tuning and Analysis Section\n",
    "\n",
    "- Random Forest\n",
    "- Linear Regression\n",
    "- Lasso\n",
    "- Ridge\n",
    "- Elastic\n",
    "- Kernel Ridge\n",
    "- Gboost\n",
    "- XGBoost\n",
    "- LightGBM\n",
    "- StackingCV Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1698,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pylab\n",
    "import math\n",
    "\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats import diagnostic as diag\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "def ignore_warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.warn = ignore_warn #ignore annoying warning (from sklearn and seaborn)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def RMSE(actual, prediction):\n",
    "    mse = mean_squared_error(actual,prediction)\n",
    "    rmse = math.sqrt(mse)\n",
    "    return(rmse)\n",
    "\n",
    "current_year_stats = ['Year', 'Player', 'Pos', 'Tm', 'G', 'GS', 'MP', 'FG', 'FGA',\n",
    "       'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA',\n",
    "       'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'Fouls', 'PTS',\n",
    "       'PY','PY2','PY3','Tm1','Tm2','Tm3']\n",
    "current_year_stats_no_player = ['Year', 'Pos', 'Tm', 'G', 'GS', 'MP', 'FG', 'FGA',\n",
    "       'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA',\n",
    "       'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'Fouls', 'PTS',\n",
    "       'PY','PY2','PY3','Tm1','Tm2','Tm3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\n",
    "alphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\n",
    "e_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\n",
    "e_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_features = features_exp.drop(current_year_stats,axis=1).dropna()\n",
    "points_features = points_features.replace('','0').astype(float)\n",
    "\n",
    "points_target = features_exp.dropna()\n",
    "points_target = points_target.PTS.replace('','0').astype(float)\n",
    "\n",
    "#points_features = points_features[['Age','PTS1','MP1','MP2','MP3','PTS2','PTS3','PG','SG','SF','PF','C','Traded','Starter']]\n",
    "x_train, x_test, y_train, y_test = train_test_split(points_features, points_target,test_size = .2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score =  0.841241654621573\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_ppg = RandomForestRegressor()#n_estimators = 100\n",
    "rf_ppg.fit(x_train, y_train)\n",
    "print('Score = ', rf_ppg.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE =  2.5521716348516796\n"
     ]
    }
   ],
   "source": [
    "y_predicted = rf_ppg.predict(x_test)\n",
    "\n",
    "print(\"RMSE = \", RMSE(y_test, y_predicted))#3.475535133855888 - 2.4746135990545777"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5149660969817984"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rm_ppg = LinearRegression()\n",
    "#fit the model\n",
    "rm_ppg.fit(x_train,y_train)\n",
    "y_predict = rm_ppg.predict(x_test)\n",
    "RMSE(y_test, y_predict)#2.7766013146219697 - #2.409100355804112"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    PTS   R-squared:                       0.844\n",
      "Model:                            OLS   Adj. R-squared:                  0.843\n",
      "Method:                 Least Squares   F-statistic:                     606.1\n",
      "Date:                Wed, 07 Oct 2020   Prob (F-statistic):               0.00\n",
      "Time:                        20:29:44   Log-Likelihood:                -13605.\n",
      "No. Observations:                5878   AIC:                         2.732e+04\n",
      "Df Residuals:                    5825   BIC:                         2.767e+04\n",
      "Df Model:                          52                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         10.1007      0.871     11.597      0.000       8.393      11.808\n",
      "Age           -0.2580      0.016    -15.808      0.000      -0.290      -0.226\n",
      "G1             0.0088      0.003      3.373      0.001       0.004       0.014\n",
      "GS1           -0.0227      0.002    -10.988      0.000      -0.027      -0.019\n",
      "MP1           -0.1261      0.017     -7.409      0.000      -0.159      -0.093\n",
      "PTS1           0.9238      0.089     10.423      0.000       0.750       1.098\n",
      "FGA1          -0.2393      0.092     -2.598      0.009      -0.420      -0.059\n",
      "FG%1          -0.4729      3.637     -0.130      0.897      -7.604       6.658\n",
      "3PA1          -0.0563      0.071     -0.792      0.429      -0.196       0.083\n",
      "3P%1          -0.0376      0.284     -0.133      0.894      -0.594       0.518\n",
      "eFG%1         -3.1777      3.529     -0.901      0.368     -10.095       3.740\n",
      "FTA1          -0.0549      0.092     -0.597      0.551      -0.235       0.125\n",
      "FT%1           0.1032      0.503      0.205      0.837      -0.883       1.089\n",
      "TRB1           0.1104      0.045      2.474      0.013       0.023       0.198\n",
      "AST1           0.1747      0.054      3.245      0.001       0.069       0.280\n",
      "STL1           0.4151      0.165      2.513      0.012       0.091       0.739\n",
      "BLK1           0.2156      0.146      1.480      0.139      -0.070       0.501\n",
      "TOV1          -0.0913      0.132     -0.690      0.490      -0.351       0.168\n",
      "MP2            0.0027      0.018      0.147      0.884      -0.033       0.038\n",
      "PTS2           0.3460      0.096      3.619      0.000       0.159       0.533\n",
      "FGA2          -0.2477      0.100     -2.480      0.013      -0.444      -0.052\n",
      "FG%2           3.9956      4.296      0.930      0.352      -4.426      12.417\n",
      "3PA2           0.0087      0.086      0.101      0.920      -0.160       0.177\n",
      "3P%2           0.1398      0.280      0.498      0.618      -0.410       0.689\n",
      "eFG%2         -5.0250      4.152     -1.210      0.226     -13.164       3.114\n",
      "FTA2          -0.0967      0.098     -0.989      0.323      -0.288       0.095\n",
      "FT%2           0.2507      0.552      0.454      0.650      -0.832       1.334\n",
      "TRB2          -0.0608      0.052     -1.178      0.239      -0.162       0.040\n",
      "AST2           0.0348      0.063      0.556      0.578      -0.088       0.158\n",
      "STL2          -0.0806      0.179     -0.450      0.653      -0.432       0.270\n",
      "BLK2           0.0957      0.151      0.631      0.528      -0.201       0.393\n",
      "TOV2          -0.1343      0.139     -0.965      0.335      -0.407       0.139\n",
      "MP3           -0.0292      0.016     -1.813      0.070      -0.061       0.002\n",
      "PTS3           0.0757      0.091      0.835      0.404      -0.102       0.253\n",
      "FGA3           0.0330      0.094      0.352      0.725      -0.151       0.217\n",
      "FG%3          -4.4919      3.837     -1.171      0.242     -12.013       3.029\n",
      "3PA3           0.0878      0.074      1.194      0.233      -0.056       0.232\n",
      "3P%3           0.6464      0.274      2.359      0.018       0.109       1.184\n",
      "eFG%3          3.4745      3.780      0.919      0.358      -3.935      10.884\n",
      "FTA3          -0.1138      0.091     -1.247      0.212      -0.293       0.065\n",
      "FT%3          -0.4458      0.545     -0.819      0.413      -1.513       0.622\n",
      "TRB3           0.0643      0.046      1.406      0.160      -0.025       0.154\n",
      "AST3          -0.0632      0.055     -1.152      0.249      -0.171       0.044\n",
      "STL3          -0.2357      0.164     -1.435      0.151      -0.558       0.086\n",
      "BLK3          -0.1010      0.134     -0.756      0.450      -0.363       0.161\n",
      "TOV3           0.2643      0.129      2.054      0.040       0.012       0.517\n",
      "C              1.5665      0.205      7.632      0.000       1.164       1.969\n",
      "PF             2.0169      0.192     10.532      0.000       1.641       2.392\n",
      "PG             1.9699      0.208      9.490      0.000       1.563       2.377\n",
      "SF             2.2241      0.185     12.024      0.000       1.861       2.587\n",
      "SG             2.3232      0.196     11.883      0.000       1.940       2.706\n",
      "Traded        -0.5877      0.069     -8.511      0.000      -0.723      -0.452\n",
      "Starter        3.3918      0.085     39.984      0.000       3.225       3.558\n",
      "Years_Pro      0.0374      0.016      2.282      0.023       0.005       0.069\n",
      "==============================================================================\n",
      "Omnibus:                      150.725   Durbin-Watson:                   1.978\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              224.924\n",
      "Skew:                           0.267   Prob(JB):                     1.44e-49\n",
      "Kurtosis:                       3.796   Cond. No.                     3.25e+15\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 5.99e-24. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n",
      "p-value = 1.071e-42\n",
      "Reject the null, there is heteroscedasticity\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "-1.931349866621653e-14"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2 = sm.add_constant(x_train)\n",
    "#create OLS model\n",
    "model = sm.OLS(y_train,X2)\n",
    "est_ppg = model.fit()\n",
    "print(est_ppg.summary())\n",
    "_, pval, _, f_pval = diag.het_breuschpagan(est_ppg.resid,est_ppg.model.exog)\n",
    "#print(pval,f_pval)\n",
    "if pval > 0.05:\n",
    "    print(\"p-value = {:.4}\".format(pval))\n",
    "    print('fail to reject the null, so there is no heteroscedasticity')\n",
    "else:\n",
    "    print(\"p-value = {:.4}\".format(pval))\n",
    "    print('Reject the null, there is heteroscedasticity')\n",
    "#check for normality of residuals\n",
    "sm.qqplot(est_ppg.resid,line='s')\n",
    "pylab.show()\n",
    "#check that mean of residuals is approx 0\n",
    "mean_residuals = sum(est_ppg.resid) / len(est_ppg.resid)\n",
    "mean_residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.001}\n",
      "-6.226233527054961\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.406523777321375"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
    "\n",
    "lasso = Lasso()\n",
    "params = {'alpha':[1e-15,1e-10, 1e-8, 1e-4, 1e-3, 1e-2,1, 5, 10, 20, 50,1e1, 1e2, 1e3, 1e5]}\n",
    "lasso_regressor = GridSearchCV(lasso, params, scoring = 'neg_mean_squared_error',cv=5)\n",
    "lasso_regressor.fit(x_train,y_train)\n",
    "print(lasso_regressor.best_params_)\n",
    "print(lasso_regressor.best_score_)\n",
    "\n",
    "predict_lasso = lasso_regressor.predict(x_test)\n",
    "RMSE(y_test,predict_lasso)#2.7368977967805495"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4070469370637873"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "kfolds = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "lasso_regressor = make_pipeline(RobustScaler(), LassoCV(max_iter=1e7, alphas=alphas2, random_state=42, cv=kfolds))\n",
    "\n",
    "lasso_regressor.fit(x_train,y_train)\n",
    "\n",
    "predict_lasso = lasso_regressor.predict(x_test)\n",
    "RMSE(y_test,predict_lasso)#2.7727925322842575"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ridge**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 10}\n",
      "-6.104540243529945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.514744396418436"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeCV, Ridge\n",
    "\n",
    "ridge = Ridge()\n",
    "params = {'alpha':[10, 20, 50,1e1, 1e2, 1e3, 1e5]}\n",
    "ridge_regressor = GridSearchCV(ridge, params, scoring = 'neg_mean_squared_error',cv=5)\n",
    "ridge_regressor.fit(x_train,y_train)\n",
    "print(ridge_regressor.best_params_)\n",
    "print(ridge_regressor.best_score_)\n",
    "predict_ridge = ridge_regressor.predict(x_test)\n",
    "RMSE(y_test,predict_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 10}\n",
      "-6.104540243529945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.514744396418436"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeCV, Ridge\n",
    "\n",
    "ridge = Ridge()\n",
    "params = {'alpha':[10, 20, 50,1e1, 1e2, 1e3, 1e5]}\n",
    "ridge_regressor = GridSearchCV(ridge, params, scoring = 'neg_mean_squared_error',cv=5)\n",
    "ridge_regressor.fit(x_train,y_train)\n",
    "print(ridge_regressor.best_params_)\n",
    "print(ridge_regressor.best_score_)\n",
    "predict_ridge = ridge_regressor.predict(x_test)\n",
    "RMSE(y_test,predict_ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Elastic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.001}\n",
      "-6.104125525103142\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.5147426696315134"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "elastic = ElasticNet()\n",
    "params = {'alpha':[1e-15,1e-10, 1e-8, 1e-4, 1e-3, 1e-2,1, 5, 10, 20, 50,1e1, 1e2, 1e3, 1e5]}\n",
    "elastic_regressor = GridSearchCV(elastic, params, scoring = 'neg_mean_squared_error',cv=5)\n",
    "elastic_regressor.fit(x_train, y_train)\n",
    "\n",
    "print(elastic_regressor.best_params_)\n",
    "print(elastic_regressor.best_score_)\n",
    "predict_elastic = elastic_regressor.predict(x_test)\n",
    "RMSE(y_test,predict_elastic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.77372692528638"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNetCV\n",
    "\n",
    "elastic_regressor = make_pipeline(RobustScaler(), ElasticNetCV(max_iter=1e7, alphas=e_alphas, cv=kfolds, l1_ratio=e_l1ratio))  \n",
    "elastic_regressor.fit(x_train, y_train)\n",
    "predict_elastic = elastic_regressor.predict(x_test)\n",
    "RMSE(y_test,predict_elastic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kernel Ridge**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0}\n",
      "-6.1172380208702615\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.514958045916307"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "krr = KernelRidge(alpha=1000)\n",
    "params = {'alpha':[1,0]}\n",
    "krr_regressor = GridSearchCV(krr, params, scoring = 'neg_mean_squared_error',cv=5)\n",
    "krr_regressor.fit(x_train, y_train)\n",
    "\n",
    "print(krr_regressor.best_params_)\n",
    "print(krr_regressor.best_score_)\n",
    "\n",
    "predict_krr = krr_regressor.predict(x_test)\n",
    "RMSE(y_test,predict_krr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gboost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.517318682540105"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gboost = GradientBoostingRegressor()\n",
    "gboost_regressor = gboost.fit(x_train,y_train)\n",
    "predict_gboost = gboost_regressor.predict(x_test)\n",
    "\n",
    "RMSE(y_test,predict_gboost) #0.12879455202929072 - 3000 0.1287189253192443- 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "# params = {'n_estimators':[4000], 'learning_rate':[.01,.1], 'max_depth':[5,10]}#, 'min_samples_leaf':[25], 'min_samples_split':[20,25],'random_state':[10,15]}\n",
    "# tuning=GridSearchCV(estimator = GradientBoostingRegressor(), param_grid = params, scoring='r2')\n",
    "# tuning.fit(x_train,y_train)\n",
    "# tuning.best_params_, tuning.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.313057587610187"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gboost = GradientBoostingRegressor(n_estimators=1000, learning_rate=0.05, max_depth=2, max_features='sqrt', min_samples_leaf=10, min_samples_split=25, loss='huber', random_state =10)\n",
    "gboost = GradientBoostingRegressor(n_estimators=4000, learning_rate=0.01, max_depth=5, max_features='sqrt', min_samples_leaf=25, min_samples_split=20, loss='huber', random_state =15)\n",
    "gboost = GradientBoostingRegressor()\n",
    "gboost_regressor = gboost.fit(x_train,y_train)\n",
    "predict_gboost = gboost_regressor.predict(x_test)\n",
    "\n",
    "RMSE(y_test,predict_gboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.666696415247867"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgboost = XGBRegressor()\n",
    "\n",
    "xgboost_regressor = xgboost.fit(x_train.values,y_train.values)\n",
    "predict_xgboost = xgboost_regressor.predict(x_test.values)\n",
    "\n",
    "RMSE(y_test,predict_xgboost) #3.418322967389393"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'learning_rate': [.05], 'n_estimators': [475], 'max_depth':[3],'min_child_weight':[0], 'gamma':[0], 'subsample':[0.5],\n",
    "          'colsample_bytree':[1],'nthread':[-1],'scale_pos_weight':[1], 'seed':[20], 'reg_alpha':[1e-5]}\n",
    "tuning=GridSearchCV(estimator = XGBRegressor(), param_grid = params, scoring='r2')\n",
    "tuning.fit(x_train,y_train)\n",
    "tuning.best_params_, tuning.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5043938838316415"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgboost = XGBRegressor(learning_rate=0.05,n_estimators=475,\n",
    "                                     max_depth=3, min_child_weight=0,\n",
    "                                     gamma=0, subsample=0.5,\n",
    "                                     colsample_bytree=1,\n",
    "                                     objective='reg:squarederror', nthread=-1,\n",
    "                                     scale_pos_weight=1, seed=20,\n",
    "                                     reg_alpha=1e-5)\n",
    "\n",
    "xgboost_regressor = xgboost.fit(x_train.values,y_train.values)\n",
    "predict_xgboost = xgboost_regressor.predict(x_test.values)\n",
    "\n",
    "RMSE(y_test,predict_xgboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LightGBM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1e-15}\n",
      "-6.272215598120032\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.4942314542942503"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "#lightgbm = LGBMRegressor(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)\n",
    "lightgbm = LGBMRegressor()\n",
    "params = {'alpha':[1e-15,1e-10, 1e-8, 1e-4, 1e-3, 1e-2,1, 5, 10, 20, 50,1e1, 1e2, 1e3, 1e5]}\n",
    "lightgbm_regressor = GridSearchCV(lightgbm, params, scoring = 'neg_mean_squared_error',cv=5)\n",
    "lightgbm_regressor.fit(x_train, y_train)\n",
    "\n",
    "print(lightgbm_regressor.best_params_)\n",
    "print(lightgbm_regressor.best_score_)\n",
    "predict_lightgbm = lightgbm_regressor.predict(x_test)\n",
    "\n",
    "RMSE(y_test,predict_lightgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.3979636925785965"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lightgbm_regressor = LGBMRegressor(objective='regression', \n",
    "                                       num_leaves=4,\n",
    "                                       learning_rate=0.01, \n",
    "                                       n_estimators=5000,\n",
    "                                       max_bin=200, \n",
    "                                       bagging_fraction=0.75,\n",
    "                                       bagging_freq=5, \n",
    "                                       bagging_seed=7,\n",
    "                                       feature_fraction=0.2,\n",
    "                                       feature_fraction_seed=7,\n",
    "                                       verbose=-1,\n",
    "                                       )\n",
    "lightgbm_regressor.fit(x_train, y_train)\n",
    "\n",
    "predict_lightgbm = lightgbm_regressor.predict(x_test)\n",
    "\n",
    "RMSE(y_test,predict_lightgbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**StackingCV Regressor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4763014316845684"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlxtend.regressor import StackingCVRegressor\n",
    "\n",
    "stack_gen = StackingCVRegressor(regressors=(rm_ppg, rf_ppg, ridge_regressor, lasso_regressor, elastic_regressor, krr_regressor, gboost_regressor, xgboost_regressor, lightgbm_regressor),\n",
    "                                meta_regressor=xgboost,\n",
    "                                use_features_in_secondary=True)\n",
    "stack_gen_model = stack_gen.fit(x_train, y_train)\n",
    "stack_gen_model_predict = stack_gen_model.predict(np.array(x_test))\n",
    "RMSE(stack_gen_model_predict, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_gen_model_list = []\n",
    "for i in stack_gen_model.predict(np.array(x_test)):\n",
    "    a = []\n",
    "    a.append(i)\n",
    "    stack_gen_model_list.append(a)\n",
    "stack_gen_model_array = np.asarray(stack_gen_model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regression_model 2.7766013146219697\n",
      "rf 3.475535133855888\n",
      "ridge_regressor 2.7439087394526376\n",
      "lasso_regressor 2.7727925322842575\n",
      "elastic_regressor 2.7352883175830836\n",
      "krr_regressor 2.775932127238594\n",
      "gboost_regressor 3.2781945344685735\n",
      "xgboost_regressor 3.2816928918626247\n",
      "lightgbm_regressor 3.3094843036120163\n"
     ]
    }
   ],
   "source": [
    "models = [rm_ppg, rf_ppg, ridge_regressor, lasso_regressor, elastic_regressor, krr_regressor, gboost_regressor, xgboost_regressor, lightgbm_regressor]\n",
    "models_str = ['regression_model', 'rf', 'ridge_regressor', 'lasso_regressor', 'elastic_regressor', 'krr_regressor', 'gboost_regressor', 'xgboost_regressor', 'lightgbm_regressor']\n",
    "ctr=0\n",
    "for i in models:\n",
    "    if i == 'stack_gen_model':\n",
    "        pass\n",
    "    else:\n",
    "        print(models_str[ctr], RMSE(i.predict(x_test),y_test))\n",
    "    ctr+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.922712310736132"
      ]
     },
     "execution_count": 560,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 10\n",
    "RMSE(list(map(sum, zip(rm_ppg.predict(x_test) * 1/n, \n",
    "                  rf_ppg.predict(x_test) * 1/n,\n",
    "                  ridge_regressor.predict(x_test) * 1/n,\n",
    "                  lasso_regressor.predict(x_test) * 1/n,\n",
    "                  elastic_regressor.predict(x_test) * 1/n,\n",
    "                  krr_regressor.predict(x_test) * 1/n,\n",
    "                  gboost_regressor.predict(x_test) * 1/n,\n",
    "                  xgboost_regressor.predict(x_test.values) * 1/n , \n",
    "                  lightgbm_regressor.predict(x_test) * 1/n,\n",
    "                  stack_gen_model_array * 1/n,\n",
    "                   )))\n",
    "      , y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Blended_Models(features):\n",
    "    n = 10\n",
    "    stack_gen_model_predict = stack_gen_model.predict(np.array(features))\n",
    "    stack_gen_model_list = []\n",
    "    for i in stack_gen_model.predict(np.array(features)):\n",
    "        a = []\n",
    "        a.append(i)\n",
    "        stack_gen_model_list.append(a)\n",
    "    stack_gen_model_array = np.asarray(stack_gen_model_list)\n",
    "    \n",
    "    return list(map(sum, zip(rm_ppg.predict(features) * 1/n, \n",
    "                  rf_ppg.predict(features) * 1/n,\n",
    "                  ridge_regressor.predict(features) * 1/n,\n",
    "                  lasso_regressor.predict(features) * 1/n,\n",
    "                  elastic_regressor.predict(features) * 1/n,\n",
    "                  krr_regressor.predict(features) * 1/n,\n",
    "                  gboost_regressor.predict(features) * 1/n,\n",
    "                  xgboost_regressor.predict(features.values) * 1/n , \n",
    "                  lightgbm_regressor.predict(features) * 1/n,\n",
    "                  stack_gen_model_array * 1/n,\n",
    "                   )))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
